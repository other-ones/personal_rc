INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'sample_max_value', 'variance_type', 'prediction_type', 'dynamic_thresholding_ratio', 'thresholding', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'resnet_out_scale_factor', 'num_class_embeds', 'dual_cross_attention', 'time_embedding_type', 'class_embed_type', 'addition_time_embed_dim', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'time_cond_proj_dim', 'transformer_layers_per_block', 'time_embedding_act_fn', 'cross_attention_norm', 'encoder_hid_dim_type', 'use_linear_projection', 'resnet_time_scale_shift', 'encoder_hid_dim', 'addition_embed_type', 'mid_block_type', 'class_embeddings_concat', 'addition_embed_type_num_heads', 'upcast_attention', 'time_embedding_dim', 'num_attention_heads', 'mid_block_only_cross_attention', 'conv_in_kernel', 'only_cross_attention', 'conv_out_kernel', 'resnet_skip_time_act'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:24<?, ?it/s, loss=0.193, loss_mlm=0.992, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:24<6846:41:28, 24.65s/it, loss=0.193, loss_mlm=0.992, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:43<6846:41:28, 24.65s/it, loss=0.396, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=8.42] Steps:   0%|          | 2/1000000 [00:43<5909:18:12, 21.27s/it, loss=0.396, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 2/1000000 [01:02<5909:18:12, 21.27s/it, loss=0.0813, loss_mlm=0.926, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 3/1000000 [01:02<5607:54:34, 20.19s/it, loss=0.0813, loss_mlm=0.926, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 3/1000000 [01:21<5607:54:34, 20.19s/it, loss=0.00572, loss_mlm=0.78, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 4/1000000 [01:21<5459:33:06, 19.65s/it, loss=0.00572, loss_mlm=0.78, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 4/1000000 [01:40<5459:33:06, 19.65s/it, loss=0.0226, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=8.89] Steps:   0%|          | 5/1000000 [01:40<5367:57:05, 19.32s/it, loss=0.0226, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 5/1000000 [01:51<5367:57:05, 19.32s/it, loss=0.11, loss_mlm=0.843, lr=0.004, norm_mask=8.02, norm_target=8.89] Steps:   0%|          | 6/1000000 [01:51<4610:59:00, 16.60s/it, loss=0.11, loss_mlm=0.843, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 6/1000000 [02:02<4610:59:00, 16.60s/it, loss=0.11, loss_mlm=0.997, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 7/1000000 [02:02<4132:06:58, 14.88s/it, loss=0.11, loss_mlm=0.997, lr=0.004, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 7/1000000 [02:13<4132:06:58, 14.88s/it, loss=0.0734, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 8/1000000 [02:13<3817:34:24, 13.74s/it, loss=0.0734, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 8/1000000 [02:25<3817:34:24, 13.74s/it, loss=0.162, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=9.51] Steps:   0%|          | 9/1000000 [02:25<3605:13:33, 12.98s/it, loss=0.162, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 9/1000000 [02:36<3605:13:33, 12.98s/it, loss=0.0933, loss_mlm=0.784, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 10/1000000 [02:36<3462:02:58, 12.46s/it, loss=0.0933, loss_mlm=0.784, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 10/1000000 [02:47<3462:02:58, 12.46s/it, loss=0.0374, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=9.51] Steps:   0%|          | 11/1000000 [02:47<3363:24:32, 12.11s/it, loss=0.0374, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=9.51]Steps:   0%|          | 11/1000000 [02:59<3363:24:32, 12.11s/it, loss=0.116, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=10.1]  Steps:   0%|          | 12/1000000 [02:59<3295:59:25, 11.87s/it, loss=0.116, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 12/1000000 [03:10<3295:59:25, 11.87s/it, loss=0.081, loss_mlm=0.934, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 13/1000000 [03:10<3249:28:16, 11.70s/it, loss=0.081, loss_mlm=0.934, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 13/1000000 [03:21<3249:28:16, 11.70s/it, loss=0.11, loss_mlm=1.22, lr=0.004, norm_mask=8.02, norm_target=10.1]  Steps:   0%|          | 14/1000000 [03:21<3216:46:58, 11.58s/it, loss=0.11, loss_mlm=1.22, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 14/1000000 [03:33<3216:46:58, 11.58s/it, loss=0.0221, loss_mlm=0.801, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 15/1000000 [03:33<3193:39:11, 11.50s/it, loss=0.0221, loss_mlm=0.801, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 15/1000000 [03:44<3193:39:11, 11.50s/it, loss=0.331, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.6]  Steps:   0%|          | 16/1000000 [03:44<3177:00:21, 11.44s/it, loss=0.331, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 16/1000000 [03:55<3177:00:21, 11.44s/it, loss=0.014, loss_mlm=0.796, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 17/1000000 [03:55<3165:59:31, 11.40s/it, loss=0.014, loss_mlm=0.796, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 17/1000000 [04:07<3165:59:31, 11.40s/it, loss=0.252, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=10.6]  Steps:   0%|          | 18/1000000 [04:07<3157:34:19, 11.37s/it, loss=0.252, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 18/1000000 [04:18<3157:34:19, 11.37s/it, loss=0.0117, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 19/1000000 [04:18<3180:11:42, 11.45s/it, loss=0.0117, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 19/1000000 [04:29<3180:11:42, 11.45s/it, loss=0.00281, loss_mlm=0.735, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 20/1000000 [04:29<3167:53:21, 11.40s/it, loss=0.00281, loss_mlm=0.735, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 20/1000000 [04:41<3167:53:21, 11.40s/it, loss=0.0633, loss_mlm=0.897, lr=0.004, norm_mask=8.02, norm_target=11.1] Steps:   0%|          | 21/1000000 [04:41<3159:26:07, 11.37s/it, loss=0.0633, loss_mlm=0.897, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 21/1000000 [04:52<3159:26:07, 11.37s/it, loss=0.125, loss_mlm=0.835, lr=0.004, norm_mask=8.02, norm_target=11.1] Steps:   0%|          | 22/1000000 [04:52<3161:52:48, 11.38s/it, loss=0.125, loss_mlm=0.835, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 22/1000000 [05:04<3161:52:48, 11.38s/it, loss=0.0691, loss_mlm=0.737, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 23/1000000 [05:04<3156:43:20, 11.36s/it, loss=0.0691, loss_mlm=0.737, lr=0.004, norm_mask=8.02, norm_target=11.1]Steps:   0%|          | 23/1000000 [05:15<3156:43:20, 11.36s/it, loss=0.124, loss_mlm=0.836, lr=0.004, norm_mask=8.02, norm_target=11.5] Steps:   0%|          | 24/1000000 [05:15<3158:55:55, 11.37s/it, loss=0.124, loss_mlm=0.836, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 24/1000000 [05:26<3158:55:55, 11.37s/it, loss=0.091, loss_mlm=0.779, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 25/1000000 [05:26<3152:30:33, 11.35s/it, loss=0.091, loss_mlm=0.779, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 25/1000000 [05:37<3152:30:33, 11.35s/it, loss=0.138, loss_mlm=1.17, lr=0.004, norm_mask=8.02, norm_target=11.5] Steps:   0%|          | 26/1000000 [05:37<3147:57:04, 11.33s/it, loss=0.138, loss_mlm=1.17, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 26/1000000 [05:49<3147:57:04, 11.33s/it, loss=0.0417, loss_mlm=0.991, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 27/1000000 [05:49<3145:21:31, 11.32s/it, loss=0.0417, loss_mlm=0.991, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 27/1000000 [06:00<3145:21:31, 11.32s/it, loss=0.11, loss_mlm=0.634, lr=0.004, norm_mask=8.02, norm_target=11.9]  Steps:   0%|          | 28/1000000 [06:00<3144:27:54, 11.32s/it, loss=0.11, loss_mlm=0.634, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 28/1000000 [06:11<3144:27:54, 11.32s/it, loss=0.122, loss_mlm=0.782, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 29/1000000 [06:11<3143:14:02, 11.32s/it, loss=0.122, loss_mlm=0.782, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 29/1000000 [06:23<3143:14:02, 11.32s/it, loss=0.135, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=11.9] Steps:   0%|          | 30/1000000 [06:23<3142:23:08, 11.31s/it, loss=0.135, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 30/1000000 [06:34<3142:23:08, 11.31s/it, loss=0.128, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 31/1000000 [06:34<3141:20:50, 11.31s/it, loss=0.128, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 31/1000000 [06:45<3141:20:50, 11.31s/it, loss=0.063, loss_mlm=0.594, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 32/1000000 [06:45<3140:38:23, 11.31s/it, loss=0.063, loss_mlm=0.594, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 32/1000000 [06:57<3140:38:23, 11.31s/it, loss=0.133, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=12.3] Steps:   0%|          | 33/1000000 [06:57<3140:14:49, 11.31s/it, loss=0.133, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 33/1000000 [07:08<3140:14:49, 11.31s/it, loss=0.102, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 34/1000000 [07:08<3139:52:23, 11.30s/it, loss=0.102, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 34/1000000 [07:19<3139:52:23, 11.30s/it, loss=0.0206, loss_mlm=0.738, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 35/1000000 [07:19<3139:09:29, 11.30s/it, loss=0.0206, loss_mlm=0.738, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 35/1000000 [07:31<3139:09:29, 11.30s/it, loss=0.108, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=12.7]  Steps:   0%|          | 36/1000000 [07:31<3139:41:52, 11.30s/it, loss=0.108, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 36/1000000 [07:42<3139:41:52, 11.30s/it, loss=0.021, loss_mlm=0.776, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 37/1000000 [07:42<3139:31:05, 11.30s/it, loss=0.021, loss_mlm=0.776, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 37/1000000 [07:53<3139:31:05, 11.30s/it, loss=0.0998, loss_mlm=0.931, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 38/1000000 [07:53<3139:26:21, 11.30s/it, loss=0.0998, loss_mlm=0.931, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 38/1000000 [08:04<3139:26:21, 11.30s/it, loss=0.0156, loss_mlm=0.903, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 39/1000000 [08:04<3140:04:17, 11.30s/it, loss=0.0156, loss_mlm=0.903, lr=0.004, norm_mask=8.02, norm_target=12.7]Steps:   0%|          | 39/1000000 [08:16<3140:04:17, 11.30s/it, loss=0.063, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=13]    Steps:   0%|          | 40/1000000 [08:16<3165:13:27, 11.40s/it, loss=0.063, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 40/1000000 [08:27<3165:13:27, 11.40s/it, loss=0.0206, loss_mlm=0.747, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 41/1000000 [08:27<3156:46:29, 11.36s/it, loss=0.0206, loss_mlm=0.747, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 41/1000000 [08:39<3156:46:29, 11.36s/it, loss=0.0484, loss_mlm=0.891, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 42/1000000 [08:39<3152:09:03, 11.35s/it, loss=0.0484, loss_mlm=0.891, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 42/1000000 [08:50<3152:09:03, 11.35s/it, loss=0.178, loss_mlm=0.913, lr=0.004, norm_mask=8.02, norm_target=13] Steps:   0%|          | 43/1000000 [08:50<3148:21:36, 11.33s/it, loss=0.178, loss_mlm=0.913, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 43/1000000 [09:01<3148:21:36, 11.33s/it, loss=0.256, loss_mlm=0.988, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 44/1000000 [09:01<3145:15:50, 11.32s/it, loss=0.256, loss_mlm=0.988, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 44/1000000 [09:13<3145:15:50, 11.32s/it, loss=0.0632, loss_mlm=0.847, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 45/1000000 [09:13<3143:51:42, 11.32s/it, loss=0.0632, loss_mlm=0.847, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 45/1000000 [09:24<3143:51:42, 11.32s/it, loss=0.0198, loss_mlm=0.626, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 46/1000000 [09:24<3142:24:50, 11.31s/it, loss=0.0198, loss_mlm=0.626, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 46/1000000 [09:35<3142:24:50, 11.31s/it, loss=0.182, loss_mlm=0.913, lr=0.004, norm_mask=8.02, norm_target=13.4] Steps:   0%|          | 47/1000000 [09:35<3141:31:31, 11.31s/it, loss=0.182, loss_mlm=0.913, lr=0.004, norm_mask=8.02, norm_target=13.4]Steps:   0%|          | 47/1000000 [09:46<3141:31:31, 11.31s/it, loss=0.189, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=13.8] Steps:   0%|          | 48/1000000 [09:46<3140:53:21, 11.31s/it, loss=0.189, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 48/1000000 [09:58<3140:53:21, 11.31s/it, loss=0.00862, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 49/1000000 [09:58<3139:55:09, 11.30s/it, loss=0.00862, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 49/1000000 [10:09<3139:55:09, 11.30s/it, loss=0.0116, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=13.8] Steps:   0%|          | 50/1000000 [10:09<3139:32:49, 11.30s/it, loss=0.0116, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 50/1000000 [10:20<3139:32:49, 11.30s/it, loss=0.0153, loss_mlm=0.924, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 51/1000000 [10:20<3139:20:21, 11.30s/it, loss=0.0153, loss_mlm=0.924, lr=0.004, norm_mask=8.02, norm_target=13.8]Steps:   0%|          | 51/1000000 [10:32<3139:20:21, 11.30s/it, loss=0.241, loss_mlm=1.17, lr=0.004, norm_mask=8.02, norm_target=14.1]  Steps:   0%|          | 52/1000000 [10:32<3138:53:35, 11.30s/it, loss=0.241, loss_mlm=1.17, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 52/1000000 [10:43<3138:53:35, 11.30s/it, loss=0.0848, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 53/1000000 [10:43<3139:12:00, 11.30s/it, loss=0.0848, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 53/1000000 [10:54<3139:12:00, 11.30s/it, loss=0.0951, loss_mlm=0.891, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 54/1000000 [10:54<3138:43:05, 11.30s/it, loss=0.0951, loss_mlm=0.891, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 54/1000000 [11:06<3138:43:05, 11.30s/it, loss=0.237, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=14.1]  Steps:   0%|          | 55/1000000 [11:06<3138:17:18, 11.30s/it, loss=0.237, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=14.1]Steps:   0%|          | 55/1000000 [11:17<3138:17:18, 11.30s/it, loss=0.218, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 56/1000000 [11:17<3138:10:25, 11.30s/it, loss=0.218, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 56/1000000 [11:28<3138:10:25, 11.30s/it, loss=0.227, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 57/1000000 [11:28<3138:01:14, 11.30s/it, loss=0.227, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 57/1000000 [11:39<3138:01:14, 11.30s/it, loss=0.165, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 58/1000000 [11:39<3137:52:48, 11.30s/it, loss=0.165, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 58/1000000 [11:51<3137:52:48, 11.30s/it, loss=0.0779, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 59/1000000 [11:51<3137:47:11, 11.30s/it, loss=0.0779, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=14.4]Steps:   0%|          | 59/1000000 [12:02<3137:47:11, 11.30s/it, loss=0.0555, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 60/1000000 [12:02<3138:03:22, 11.30s/it, loss=0.0555, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 60/1000000 [12:14<3138:03:22, 11.30s/it, loss=0.0276, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 61/1000000 [12:14<3163:35:55, 11.39s/it, loss=0.0276, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 61/1000000 [12:25<3163:35:55, 11.39s/it, loss=0.167, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.7] Steps:   0%|          | 62/1000000 [12:25<3156:26:31, 11.36s/it, loss=0.167, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 62/1000000 [12:36<3156:26:31, 11.36s/it, loss=0.091, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 63/1000000 [12:36<3150:57:33, 11.34s/it, loss=0.091, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.7]Steps:   0%|          | 63/1000000 [12:48<3150:57:33, 11.34s/it, loss=0.0417, loss_mlm=0.785, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 64/1000000 [12:48<3147:29:22, 11.33s/it, loss=0.0417, loss_mlm=0.785, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 64/1000000 [12:59<3147:29:22, 11.33s/it, loss=0.155, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=15]  Steps:   0%|          | 65/1000000 [12:59<3144:47:10, 11.32s/it, loss=0.155, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 65/1000000 [13:10<3144:47:10, 11.32s/it, loss=0.0394, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 66/1000000 [13:10<3145:33:32, 11.32s/it, loss=0.0394, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 66/1000000 [13:21<3145:33:32, 11.32s/it, loss=0.165, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=15] Steps:   0%|          | 67/1000000 [13:21<3144:06:22, 11.32s/it, loss=0.165, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=15]Steps:   0%|          | 67/1000000 [13:33<3144:06:22, 11.32s/it, loss=0.0817, loss_mlm=1.38, lr=0.004, norm_mask=8.02, norm_target=15.4]Steps:   0%|          | 68/1000000 [13:33<3141:54:58, 11.31s/it, loss=0.0817, loss_mlm=1.38, lr=0.004, norm_mask=8.02, norm_target=15.4]Steps:   0%|          | 68/1000000 [13:44<3141:54:58, 11.31s/it, loss=0.0761, loss_mlm=0.914, lr=0.004, norm_mask=8.02, norm_target=15.4]Steps:   0%|          | 69/1000000 [13:44<3140:50:52, 11.31s/it, loss=0.0761, loss_mlm=0.914, lr=0.004, norm_mask=8.02, norm_target=15.4]Steps:   0%|          | 69/1000000 [13:55<3140:50:52, 11.31s/it, loss=0.251, loss_mlm=0.978, lr=0.004, norm_mask=8.02, norm_target=15.4] Steps:   0%|          | 70/1000000 [13:55<3140:29:03, 11.31s/it, loss=0.251, loss_mlm=0.978, lr=0.004, norm_mask=8.02, norm_target=15.4]