INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'dynamic_thresholding_ratio', 'sample_max_value', 'variance_type', 'thresholding', 'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'addition_embed_type_num_heads', 'resnet_out_scale_factor', 'encoder_hid_dim_type', 'resnet_time_scale_shift', 'addition_time_embed_dim', 'transformer_layers_per_block', 'conv_out_kernel', 'dual_cross_attention', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'addition_embed_type', 'time_cond_proj_dim', 'use_linear_projection', 'mid_block_only_cross_attention', 'num_attention_heads', 'encoder_hid_dim', 'upcast_attention', 'resnet_skip_time_act', 'time_embedding_act_fn', 'cross_attention_norm', 'class_embeddings_concat', 'mid_block_type', 'class_embed_type', 'only_cross_attention', 'timestep_post_act', 'conv_in_kernel', 'time_embedding_type', 'time_embedding_dim'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:15<?, ?it/s, loss=0.193, loss_mlm=0.992, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:15<4177:41:27, 15.04s/it, loss=0.193, loss_mlm=0.992, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:33<4177:41:27, 15.04s/it, loss=0.397, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=8.42] Steps:   0%|          | 2/1000000 [00:33<4772:48:52, 17.18s/it, loss=0.397, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 2/1000000 [00:52<4772:48:52, 17.18s/it, loss=0.0822, loss_mlm=0.926, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 3/1000000 [00:52<4962:07:13, 17.86s/it, loss=0.0822, loss_mlm=0.926, lr=0.004, norm_mask=8.02, norm_target=8.42]Steps:   0%|          | 3/1000000 [01:11<4962:07:13, 17.86s/it, loss=0.00642, loss_mlm=0.78, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 4/1000000 [01:11<5059:25:56, 18.21s/it, loss=0.00642, loss_mlm=0.78, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 4/1000000 [01:29<5059:25:56, 18.21s/it, loss=0.0237, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=8.98] Steps:   0%|          | 5/1000000 [01:29<5108:30:33, 18.39s/it, loss=0.0237, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 5/1000000 [01:46<5108:30:33, 18.39s/it, loss=0.111, loss_mlm=0.831, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 6/1000000 [01:46<4917:04:47, 17.70s/it, loss=0.111, loss_mlm=0.831, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 6/1000000 [01:57<4917:04:47, 17.70s/it, loss=0.111, loss_mlm=0.982, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 7/1000000 [01:57<4335:07:39, 15.61s/it, loss=0.111, loss_mlm=0.982, lr=0.004, norm_mask=8.02, norm_target=8.98]Steps:   0%|          | 7/1000000 [02:08<4335:07:39, 15.61s/it, loss=0.0743, loss_mlm=0.999, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 8/1000000 [02:08<3956:06:51, 14.24s/it, loss=0.0743, loss_mlm=0.999, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 8/1000000 [02:20<3956:06:51, 14.24s/it, loss=0.163, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=9.57]  Steps:   0%|          | 9/1000000 [02:20<3699:57:18, 13.32s/it, loss=0.163, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 9/1000000 [02:31<3699:57:18, 13.32s/it, loss=0.094, loss_mlm=0.757, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 10/1000000 [02:31<3526:16:11, 12.69s/it, loss=0.094, loss_mlm=0.757, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 10/1000000 [02:42<3526:16:11, 12.69s/it, loss=0.0383, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 11/1000000 [02:42<3407:01:27, 12.27s/it, loss=0.0383, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=9.57]Steps:   0%|          | 11/1000000 [02:54<3407:01:27, 12.27s/it, loss=0.117, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=10.1] Steps:   0%|          | 12/1000000 [02:54<3324:51:30, 11.97s/it, loss=0.117, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 12/1000000 [03:05<3324:51:30, 11.97s/it, loss=0.0818, loss_mlm=0.91, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 13/1000000 [03:05<3268:32:55, 11.77s/it, loss=0.0818, loss_mlm=0.91, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 13/1000000 [03:16<3268:32:55, 11.77s/it, loss=0.111, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=10.1] Steps:   0%|          | 14/1000000 [03:16<3228:47:58, 11.62s/it, loss=0.111, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 14/1000000 [03:27<3228:47:58, 11.62s/it, loss=0.0226, loss_mlm=0.769, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 15/1000000 [03:27<3201:34:15, 11.53s/it, loss=0.0226, loss_mlm=0.769, lr=0.004, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 15/1000000 [03:39<3201:34:15, 11.53s/it, loss=0.332, loss_mlm=1.22, lr=0.004, norm_mask=8.02, norm_target=10.6]  Steps:   0%|          | 16/1000000 [03:39<3182:18:23, 11.46s/it, loss=0.332, loss_mlm=1.22, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 16/1000000 [03:50<3182:18:23, 11.46s/it, loss=0.0147, loss_mlm=0.763, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 17/1000000 [03:50<3169:36:27, 11.41s/it, loss=0.0147, loss_mlm=0.763, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 17/1000000 [04:01<3169:36:27, 11.41s/it, loss=0.253, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=10.6]  Steps:   0%|          | 18/1000000 [04:01<3160:52:55, 11.38s/it, loss=0.253, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 18/1000000 [04:13<3160:52:55, 11.38s/it, loss=0.0128, loss_mlm=1.26, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 19/1000000 [04:13<3181:06:07, 11.45s/it, loss=0.0128, loss_mlm=1.26, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 19/1000000 [04:24<3181:06:07, 11.45s/it, loss=0.00345, loss_mlm=0.719, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 20/1000000 [04:24<3168:17:26, 11.41s/it, loss=0.00345, loss_mlm=0.719, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 20/1000000 [04:36<3168:17:26, 11.41s/it, loss=0.0641, loss_mlm=0.87, lr=0.004, norm_mask=8.02, norm_target=11]  Steps:   0%|          | 21/1000000 [04:36<3159:37:12, 11.37s/it, loss=0.0641, loss_mlm=0.87, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 21/1000000 [04:47<3159:37:12, 11.37s/it, loss=0.126, loss_mlm=0.806, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 22/1000000 [04:47<3153:26:22, 11.35s/it, loss=0.126, loss_mlm=0.806, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 22/1000000 [04:58<3153:26:22, 11.35s/it, loss=0.0698, loss_mlm=0.719, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 23/1000000 [04:58<3147:56:01, 11.33s/it, loss=0.0698, loss_mlm=0.719, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 23/1000000 [05:09<3147:56:01, 11.33s/it, loss=0.125, loss_mlm=0.81, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 24/1000000 [05:09<3144:56:35, 11.32s/it, loss=0.125, loss_mlm=0.81, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 24/1000000 [05:21<3144:56:35, 11.32s/it, loss=0.0917, loss_mlm=0.745, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 25/1000000 [05:21<3143:55:47, 11.32s/it, loss=0.0917, loss_mlm=0.745, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 25/1000000 [05:32<3143:55:47, 11.32s/it, loss=0.139, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=11.5]  Steps:   0%|          | 26/1000000 [05:32<3141:47:42, 11.31s/it, loss=0.139, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 26/1000000 [05:43<3141:47:42, 11.31s/it, loss=0.0426, loss_mlm=0.976, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 27/1000000 [05:43<3140:33:42, 11.31s/it, loss=0.0426, loss_mlm=0.976, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 27/1000000 [05:55<3140:33:42, 11.31s/it, loss=0.111, loss_mlm=0.618, lr=0.004, norm_mask=8.02, norm_target=11.9] Steps:   0%|          | 28/1000000 [05:55<3139:35:41, 11.30s/it, loss=0.111, loss_mlm=0.618, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 28/1000000 [06:06<3139:35:41, 11.30s/it, loss=0.123, loss_mlm=0.766, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 29/1000000 [06:06<3138:13:50, 11.30s/it, loss=0.123, loss_mlm=0.766, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 29/1000000 [06:17<3138:13:50, 11.30s/it, loss=0.135, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=11.9] Steps:   0%|          | 30/1000000 [06:17<3136:48:45, 11.29s/it, loss=0.135, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 30/1000000 [06:28<3136:48:45, 11.29s/it, loss=0.129, loss_mlm=0.996, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 31/1000000 [06:28<3136:33:39, 11.29s/it, loss=0.129, loss_mlm=0.996, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 31/1000000 [06:40<3136:33:39, 11.29s/it, loss=0.0635, loss_mlm=0.562, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 32/1000000 [06:40<3137:25:39, 11.30s/it, loss=0.0635, loss_mlm=0.562, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 32/1000000 [06:51<3137:25:39, 11.30s/it, loss=0.134, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=12.3]  Steps:   0%|          | 33/1000000 [06:51<3137:09:12, 11.29s/it, loss=0.134, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 33/1000000 [07:02<3137:09:12, 11.29s/it, loss=0.103, loss_mlm=0.831, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 34/1000000 [07:02<3138:01:47, 11.30s/it, loss=0.103, loss_mlm=0.831, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 34/1000000 [07:14<3138:01:47, 11.30s/it, loss=0.0212, loss_mlm=0.727, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 35/1000000 [07:14<3136:39:31, 11.29s/it, loss=0.0212, loss_mlm=0.727, lr=0.004, norm_mask=8.02, norm_target=12.3]Steps:   0%|          | 35/1000000 [07:25<3136:39:31, 11.29s/it, loss=0.109, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=12.8]  Steps:   0%|          | 36/1000000 [07:25<3136:35:30, 11.29s/it, loss=0.109, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 36/1000000 [07:36<3136:35:30, 11.29s/it, loss=0.0217, loss_mlm=0.739, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 37/1000000 [07:36<3135:39:45, 11.29s/it, loss=0.0217, loss_mlm=0.739, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 37/1000000 [07:47<3135:39:45, 11.29s/it, loss=0.101, loss_mlm=0.905, lr=0.004, norm_mask=8.02, norm_target=12.8] Steps:   0%|          | 38/1000000 [07:47<3135:27:29, 11.29s/it, loss=0.101, loss_mlm=0.905, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 38/1000000 [07:59<3135:27:29, 11.29s/it, loss=0.0164, loss_mlm=0.881, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 39/1000000 [07:59<3135:32:42, 11.29s/it, loss=0.0164, loss_mlm=0.881, lr=0.004, norm_mask=8.02, norm_target=12.8]Steps:   0%|          | 39/1000000 [08:10<3135:32:42, 11.29s/it, loss=0.0641, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=13.2] Steps:   0%|          | 40/1000000 [08:10<3160:12:44, 11.38s/it, loss=0.0641, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 40/1000000 [08:22<3160:12:44, 11.38s/it, loss=0.0213, loss_mlm=0.727, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 41/1000000 [08:22<3152:45:39, 11.35s/it, loss=0.0213, loss_mlm=0.727, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 41/1000000 [08:33<3152:45:39, 11.35s/it, loss=0.0492, loss_mlm=0.875, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 42/1000000 [08:33<3147:29:13, 11.33s/it, loss=0.0492, loss_mlm=0.875, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 42/1000000 [08:44<3147:29:13, 11.33s/it, loss=0.179, loss_mlm=0.88, lr=0.004, norm_mask=8.02, norm_target=13.2]  Steps:   0%|          | 43/1000000 [08:44<3143:56:06, 11.32s/it, loss=0.179, loss_mlm=0.88, lr=0.004, norm_mask=8.02, norm_target=13.2]Steps:   0%|          | 43/1000000 [08:56<3143:56:06, 11.32s/it, loss=0.256, loss_mlm=0.965, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 44/1000000 [08:56<3141:18:15, 11.31s/it, loss=0.256, loss_mlm=0.965, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 44/1000000 [09:07<3141:18:15, 11.31s/it, loss=0.064, loss_mlm=0.824, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 45/1000000 [09:07<3139:51:32, 11.30s/it, loss=0.064, loss_mlm=0.824, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 45/1000000 [09:18<3139:51:32, 11.30s/it, loss=0.0204, loss_mlm=0.6, lr=0.004, norm_mask=8.02, norm_target=13.5] Steps:   0%|          | 46/1000000 [09:18<3138:53:19, 11.30s/it, loss=0.0204, loss_mlm=0.6, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 46/1000000 [09:29<3138:53:19, 11.30s/it, loss=0.183, loss_mlm=0.881, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 47/1000000 [09:29<3140:13:34, 11.31s/it, loss=0.183, loss_mlm=0.881, lr=0.004, norm_mask=8.02, norm_target=13.5]Steps:   0%|          | 47/1000000 [09:41<3140:13:34, 11.31s/it, loss=0.19, loss_mlm=1.11, lr=0.004, norm_mask=8.02, norm_target=13.9]  Steps:   0%|          | 48/1000000 [09:41<3141:19:51, 11.31s/it, loss=0.19, loss_mlm=1.11, lr=0.004, norm_mask=8.02, norm_target=13.9]Steps:   0%|          | 48/1000000 [09:52<3141:19:51, 11.31s/it, loss=0.00949, loss_mlm=0.993, lr=0.004, norm_mask=8.02, norm_target=13.9]Steps:   0%|          | 49/1000000 [09:52<3140:09:49, 11.31s/it, loss=0.00949, loss_mlm=0.993, lr=0.004, norm_mask=8.02, norm_target=13.9]Steps:   0%|          | 49/1000000 [10:03<3140:09:49, 11.31s/it, loss=0.0126, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=13.9]  Steps:   0%|          | 50/1000000 [10:03<3139:40:04, 11.30s/it, loss=0.0126, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=13.9]Steps:   0%|          | 50/1000000 [10:15<3139:40:04, 11.30s/it, loss=0.0163, loss_mlm=0.9, lr=0.004, norm_mask=8.02, norm_target=13.9] Steps:   0%|          | 51/1000000 [10:15<3137:55:35, 11.30s/it, loss=0.0163, loss_mlm=0.9, lr=0.004, norm_mask=8.02, norm_target=13.9]Steps:   0%|          | 51/1000000 [10:26<3137:55:35, 11.30s/it, loss=0.242, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 52/1000000 [10:26<3139:30:20, 11.30s/it, loss=0.242, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 52/1000000 [10:37<3139:30:20, 11.30s/it, loss=0.0859, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 53/1000000 [10:37<3138:16:31, 11.30s/it, loss=0.0859, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 53/1000000 [10:49<3138:16:31, 11.30s/it, loss=0.0959, loss_mlm=0.863, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 54/1000000 [10:49<3138:05:04, 11.30s/it, loss=0.0959, loss_mlm=0.863, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 54/1000000 [11:00<3138:05:04, 11.30s/it, loss=0.238, loss_mlm=0.978, lr=0.004, norm_mask=8.02, norm_target=14.2] Steps:   0%|          | 55/1000000 [11:00<3137:13:55, 11.29s/it, loss=0.238, loss_mlm=0.978, lr=0.004, norm_mask=8.02, norm_target=14.2]Steps:   0%|          | 55/1000000 [11:11<3137:13:55, 11.29s/it, loss=0.219, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=14.5] Steps:   0%|          | 56/1000000 [11:11<3137:22:32, 11.30s/it, loss=0.219, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 56/1000000 [11:22<3137:22:32, 11.30s/it, loss=0.228, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 57/1000000 [11:22<3137:07:25, 11.29s/it, loss=0.228, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 57/1000000 [11:34<3137:07:25, 11.29s/it, loss=0.166, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14.5] Steps:   0%|          | 58/1000000 [11:34<3137:07:09, 11.29s/it, loss=0.166, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 58/1000000 [11:45<3137:07:09, 11.29s/it, loss=0.0788, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 59/1000000 [11:45<3137:21:32, 11.30s/it, loss=0.0788, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=14.5]Steps:   0%|          | 59/1000000 [11:56<3137:21:32, 11.30s/it, loss=0.0565, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 60/1000000 [11:56<3137:15:30, 11.29s/it, loss=0.0565, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 60/1000000 [12:08<3137:15:30, 11.29s/it, loss=0.0288, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14.8] Steps:   0%|          | 61/1000000 [12:08<3162:24:48, 11.39s/it, loss=0.0288, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 61/1000000 [12:19<3162:24:48, 11.39s/it, loss=0.168, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 62/1000000 [12:19<3153:42:46, 11.35s/it, loss=0.168, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 62/1000000 [12:30<3153:42:46, 11.35s/it, loss=0.0918, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 63/1000000 [12:30<3148:07:28, 11.33s/it, loss=0.0918, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.8]Steps:   0%|          | 63/1000000 [12:42<3148:07:28, 11.33s/it, loss=0.0424, loss_mlm=0.73, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 64/1000000 [12:42<3145:07:46, 11.32s/it, loss=0.0424, loss_mlm=0.73, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 64/1000000 [12:53<3145:07:46, 11.32s/it, loss=0.156, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=15.1]  Steps:   0%|          | 65/1000000 [12:53<3142:19:03, 11.31s/it, loss=0.156, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 65/1000000 [13:04<3142:19:03, 11.31s/it, loss=0.0404, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 66/1000000 [13:04<3141:42:44, 11.31s/it, loss=0.0404, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 66/1000000 [13:16<3141:42:44, 11.31s/it, loss=0.166, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=15.1] Steps:   0%|          | 67/1000000 [13:16<3139:43:06, 11.30s/it, loss=0.166, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=15.1]Steps:   0%|          | 67/1000000 [13:27<3139:43:06, 11.30s/it, loss=0.0829, loss_mlm=1.34, lr=0.004, norm_mask=8.02, norm_target=15.4]Steps:   0%|          | 68/1000000 [13:27<3138:59:15, 11.30s/it, loss=0.0829, loss_mlm=1.34, lr=0.004, norm_mask=8.02, norm_target=15.4]