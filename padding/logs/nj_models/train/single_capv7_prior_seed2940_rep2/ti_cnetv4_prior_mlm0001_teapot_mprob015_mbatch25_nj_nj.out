INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'timestep_spacing', 'variance_type', 'sample_max_value', 'prediction_type', 'clip_sample_range', 'dynamic_thresholding_ratio', 'thresholding'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'upcast_attention', 'transformer_layers_per_block', 'num_class_embeds', 'class_embeddings_concat', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'mid_block_only_cross_attention', 'conv_in_kernel', 'addition_embed_type', 'time_embedding_act_fn', 'resnet_skip_time_act', 'use_linear_projection', 'time_embedding_type', 'cross_attention_norm', 'mid_block_type', 'class_embed_type', 'time_cond_proj_dim', 'only_cross_attention', 'timestep_post_act', 'addition_time_embed_dim', 'encoder_hid_dim_type', 'num_attention_heads', 'time_embedding_dim', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'conv_out_kernel', 'dual_cross_attention'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
saved_models/nj_models/single_capv7_prior_seed2940_rep2/teapot/ti_cnetv4_prior_mlm0001_teapot_mprob015_mbatch25_nj_nj/src/command.txt command_path
nj_train.py item
--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 item
--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/teapot item
--learnable_property=object item
--placeholder_token1=<teapot> item
--train_prior_concept1=teapot item
--eval_prior_concept1=teapot item
--resolution=512 item
--train_batch_size=1 item
--gradient_accumulation_steps=4 item
--learning_rate=5e-4 item
--lr_scheduler=constant item
--normalize_mask_embeds=0 item
--lr_warmup_steps=0 item
--output_dir=saved_models/nj_models/single_capv7_prior_seed2940_rep2/teapot item
--seed=2940 item
--mask_tokens=[MASK] item
--lambda_mlm=0 item
--freeze_mask_embedding=1 item
--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt item
--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt item
--mask_prob=0.15 item
--mlm_target=masked item
--mlm_batch_size=25 item
--scale_lr item
--eval_prompt_type=nonliving item
--train_prompt_type=nonliving item
--silent=0 item
--rev=0 item
--normalize_target1=0 item
--caption_root=../datasets_pkgs/captions/v7 item
--run_name=ti_cnetv4_prior_mlm0001_teapot_mprob015_mbatch25_nj_nj item
--include_prior_concept=1 item
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
None mask_token_ids
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
INFO:__main__:STEP 0 Running validation... 
 Generating 8 images with prompt: ['a <teapot> teapot in the jungle', 'a <teapot> teapot with a city in the background', 'a <teapot> teapot with a mountain in the background', 'a <teapot> teapot with the Eiffel Tower in the background', 'a <teapot> teapot floating on top of water', 'a <teapot> teapot floating in an ocean of milk', 'a <teapot> teapot on top of the sidewalk in a crowded street', 'a cube shaped <teapot> teapot'].

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|▍         | 1/25 [00:00<00:09,  2.57it/s][A
  8%|▊         | 2/25 [00:00<00:08,  2.79it/s][A
 12%|█▏        | 3/25 [00:01<00:07,  2.87it/s][A
 16%|█▌        | 4/25 [00:01<00:07,  2.91it/s][A
 20%|██        | 5/25 [00:01<00:06,  2.93it/s][A
 24%|██▍       | 6/25 [00:02<00:06,  2.94it/s][A
 28%|██▊       | 7/25 [00:02<00:06,  2.95it/s][A
 32%|███▏      | 8/25 [00:02<00:05,  2.95it/s][A
 36%|███▌      | 9/25 [00:03<00:05,  2.96it/s][A
 40%|████      | 10/25 [00:03<00:05,  2.96it/s][A
 44%|████▍     | 11/25 [00:03<00:04,  2.96it/s][A
 48%|████▊     | 12/25 [00:04<00:04,  2.96it/s][A
 52%|█████▏    | 13/25 [00:04<00:04,  2.96it/s][A
 56%|█████▌    | 14/25 [00:04<00:03,  2.96it/s][A
 60%|██████    | 15/25 [00:05<00:03,  2.96it/s][A
 64%|██████▍   | 16/25 [00:05<00:03,  2.96it/s][A
 68%|██████▊   | 17/25 [00:05<00:02,  2.96it/s][A
 72%|███████▏  | 18/25 [00:06<00:02,  2.96it/s][A
 76%|███████▌  | 19/25 [00:06<00:02,  2.96it/s][A
 80%|████████  | 20/25 [00:06<00:01,  2.96it/s][A
 84%|████████▍ | 21/25 [00:07<00:01,  2.96it/s][A
 88%|████████▊ | 22/25 [00:07<00:01,  2.95it/s][A
 92%|█████████▏| 23/25 [00:07<00:00,  2.96it/s][A
 96%|█████████▌| 24/25 [00:08<00:00,  2.96it/s][A
100%|██████████| 25/25 [00:08<00:00,  2.96it/s][A100%|██████████| 25/25 [00:09<00:00,  2.68it/s]
Steps:   0%|          | 0/1000000 [00:23<?, ?it/s, loss=0.179, lr=0.002, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:23<6432:39:35, 23.16s/it, loss=0.179, lr=0.002, norm_target=8.42]Steps:   0%|          | 1/1000000 [00:34<6432:39:35, 23.16s/it, loss=0.548, lr=0.002, norm_target=8.42]Steps:   0%|          | 2/1000000 [00:34<4455:33:55, 16.04s/it, loss=0.548, lr=0.002, norm_target=8.42]Steps:   0%|          | 2/1000000 [00:45<4455:33:55, 16.04s/it, loss=0.103, lr=0.002, norm_target=8.42]Steps:   0%|          | 3/1000000 [00:45<3818:10:06, 13.75s/it, loss=0.103, lr=0.002, norm_target=8.42]Steps:   0%|          | 3/1000000 [00:56<3818:10:06, 13.75s/it, loss=0.00431, lr=0.002, norm_target=8.58]Steps:   0%|          | 4/1000000 [00:56<3519:38:46, 12.67s/it, loss=0.00431, lr=0.002, norm_target=8.58]Steps:   0%|          | 4/1000000 [01:07<3519:38:46, 12.67s/it, loss=0.00343, lr=0.002, norm_target=8.58]Steps:   0%|          | 5/1000000 [01:07<3353:04:37, 12.07s/it, loss=0.00343, lr=0.002, norm_target=8.58]Steps:   0%|          | 5/1000000 [01:18<3353:04:37, 12.07s/it, loss=0.0047, lr=0.002, norm_target=8.58] Steps:   0%|          | 6/1000000 [01:18<3252:41:56, 11.71s/it, loss=0.0047, lr=0.002, norm_target=8.58]Steps:   0%|          | 6/1000000 [01:29<3252:41:56, 11.71s/it, loss=0.0245, lr=0.002, norm_target=8.58]Steps:   0%|          | 7/1000000 [01:29<3187:11:41, 11.47s/it, loss=0.0245, lr=0.002, norm_target=8.58]Steps:   0%|          | 7/1000000 [01:40<3187:11:41, 11.47s/it, loss=0.143, lr=0.002, norm_target=8.71] Steps:   0%|          | 8/1000000 [01:40<3145:50:08, 11.33s/it, loss=0.143, lr=0.002, norm_target=8.71]Steps:   0%|          | 8/1000000 [01:51<3145:50:08, 11.33s/it, loss=0.268, lr=0.002, norm_target=8.71]Steps:   0%|          | 9/1000000 [01:51<3120:40:16, 11.23s/it, loss=0.268, lr=0.002, norm_target=8.71]Steps:   0%|          | 9/1000000 [02:02<3120:40:16, 11.23s/it, loss=0.181, lr=0.002, norm_target=8.71]Steps:   0%|          | 10/1000000 [02:02<3100:30:31, 11.16s/it, loss=0.181, lr=0.002, norm_target=8.71]Steps:   0%|          | 10/1000000 [02:13<3100:30:31, 11.16s/it, loss=0.0186, lr=0.002, norm_target=8.71]Steps:   0%|          | 11/1000000 [02:13<3086:55:22, 11.11s/it, loss=0.0186, lr=0.002, norm_target=8.71]Steps:   0%|          | 11/1000000 [02:24<3086:55:22, 11.11s/it, loss=0.331, lr=0.002, norm_target=8.84] Steps:   0%|          | 12/1000000 [02:24<3077:25:05, 11.08s/it, loss=0.331, lr=0.002, norm_target=8.84]Steps:   0%|          | 12/1000000 [02:35<3077:25:05, 11.08s/it, loss=0.0849, lr=0.002, norm_target=8.84]Steps:   0%|          | 13/1000000 [02:35<3072:14:06, 11.06s/it, loss=0.0849, lr=0.002, norm_target=8.84]Steps:   0%|          | 13/1000000 [02:46<3072:14:06, 11.06s/it, loss=0.0749, lr=0.002, norm_target=8.84]Steps:   0%|          | 14/1000000 [02:46<3068:10:23, 11.05s/it, loss=0.0749, lr=0.002, norm_target=8.84]Steps:   0%|          | 14/1000000 [02:57<3068:10:23, 11.05s/it, loss=0.0159, lr=0.002, norm_target=8.84]Steps:   0%|          | 15/1000000 [02:57<3066:17:19, 11.04s/it, loss=0.0159, lr=0.002, norm_target=8.84]Steps:   0%|          | 15/1000000 [03:08<3066:17:19, 11.04s/it, loss=0.012, lr=0.002, norm_target=8.98] Steps:   0%|          | 16/1000000 [03:08<3064:57:38, 11.03s/it, loss=0.012, lr=0.002, norm_target=8.98]Steps:   0%|          | 16/1000000 [03:19<3064:57:38, 11.03s/it, loss=0.0155, lr=0.002, norm_target=8.98]Steps:   0%|          | 17/1000000 [03:19<3063:40:31, 11.03s/it, loss=0.0155, lr=0.002, norm_target=8.98]Steps:   0%|          | 17/1000000 [03:30<3063:40:31, 11.03s/it, loss=0.246, lr=0.002, norm_target=8.98] Steps:   0%|          | 18/1000000 [03:30<3062:39:04, 11.03s/it, loss=0.246, lr=0.002, norm_target=8.98]Steps:   0%|          | 18/1000000 [03:41<3062:39:04, 11.03s/it, loss=0.0188, lr=0.002, norm_target=8.98]Steps:   0%|          | 19/1000000 [03:41<3061:41:01, 11.02s/it, loss=0.0188, lr=0.002, norm_target=8.98]Steps:   0%|          | 19/1000000 [03:52<3061:41:01, 11.02s/it, loss=0.00235, lr=0.002, norm_target=9.15]Steps:   0%|          | 20/1000000 [03:52<3059:59:31, 11.02s/it, loss=0.00235, lr=0.002, norm_target=9.15]Steps:   0%|          | 20/1000000 [04:03<3059:59:31, 11.02s/it, loss=0.119, lr=0.002, norm_target=9.15]  Steps:   0%|          | 21/1000000 [04:03<3058:23:19, 11.01s/it, loss=0.119, lr=0.002, norm_target=9.15]Steps:   0%|          | 21/1000000 [04:14<3058:23:19, 11.01s/it, loss=0.237, lr=0.002, norm_target=9.15]Steps:   0%|          | 22/1000000 [04:14<3057:03:49, 11.01s/it, loss=0.237, lr=0.002, norm_target=9.15]Steps:   0%|          | 22/1000000 [04:25<3057:03:49, 11.01s/it, loss=0.0675, lr=0.002, norm_target=9.15]Steps:   0%|          | 23/1000000 [04:25<3056:41:27, 11.00s/it, loss=0.0675, lr=0.002, norm_target=9.15]Steps:   0%|          | 23/1000000 [04:36<3056:41:27, 11.00s/it, loss=0.101, lr=0.002, norm_target=9.33] Steps:   0%|          | 24/1000000 [04:36<3056:18:13, 11.00s/it, loss=0.101, lr=0.002, norm_target=9.33]Steps:   0%|          | 24/1000000 [04:47<3056:18:13, 11.00s/it, loss=0.143, lr=0.002, norm_target=9.33]Steps:   0%|          | 25/1000000 [04:47<3055:43:36, 11.00s/it, loss=0.143, lr=0.002, norm_target=9.33]Steps:   0%|          | 25/1000000 [04:58<3055:43:36, 11.00s/it, loss=0.0101, lr=0.002, norm_target=9.33]Steps:   0%|          | 26/1000000 [04:58<3055:31:49, 11.00s/it, loss=0.0101, lr=0.002, norm_target=9.33]Steps:   0%|          | 26/1000000 [05:09<3055:31:49, 11.00s/it, loss=0.0147, lr=0.002, norm_target=9.33]Steps:   0%|          | 27/1000000 [05:09<3055:14:14, 11.00s/it, loss=0.0147, lr=0.002, norm_target=9.33]Steps:   0%|          | 27/1000000 [05:20<3055:14:14, 11.00s/it, loss=0.0203, lr=0.002, norm_target=9.48]Steps:   0%|          | 28/1000000 [05:20<3055:04:41, 11.00s/it, loss=0.0203, lr=0.002, norm_target=9.48]Steps:   0%|          | 28/1000000 [05:31<3055:04:41, 11.00s/it, loss=0.177, lr=0.002, norm_target=9.48] Steps:   0%|          | 29/1000000 [05:31<3055:09:06, 11.00s/it, loss=0.177, lr=0.002, norm_target=9.48]Steps:   0%|          | 29/1000000 [05:42<3055:09:06, 11.00s/it, loss=0.0788, lr=0.002, norm_target=9.48]Steps:   0%|          | 30/1000000 [05:42<3055:04:39, 11.00s/it, loss=0.0788, lr=0.002, norm_target=9.48]Steps:   0%|          | 30/1000000 [05:53<3055:04:39, 11.00s/it, loss=0.214, lr=0.002, norm_target=9.48] Steps:   0%|          | 31/1000000 [05:53<3055:58:46, 11.00s/it, loss=0.214, lr=0.002, norm_target=9.48]Steps:   0%|          | 31/1000000 [06:04<3055:58:46, 11.00s/it, loss=0.201, lr=0.002, norm_target=9.63]Steps:   0%|          | 32/1000000 [06:04<3055:47:58, 11.00s/it, loss=0.201, lr=0.002, norm_target=9.63]Steps:   0%|          | 32/1000000 [06:15<3055:47:58, 11.00s/it, loss=0.203, lr=0.002, norm_target=9.63]Steps:   0%|          | 33/1000000 [06:15<3082:46:02, 11.10s/it, loss=0.203, lr=0.002, norm_target=9.63]Steps:   0%|          | 33/1000000 [06:26<3082:46:02, 11.10s/it, loss=0.0661, lr=0.002, norm_target=9.63]Steps:   0%|          | 34/1000000 [06:26<3075:43:29, 11.07s/it, loss=0.0661, lr=0.002, norm_target=9.63]Steps:   0%|          | 34/1000000 [06:37<3075:43:29, 11.07s/it, loss=0.0485, lr=0.002, norm_target=9.63]Steps:   0%|          | 35/1000000 [06:37<3070:26:21, 11.05s/it, loss=0.0485, lr=0.002, norm_target=9.63]Steps:   0%|          | 35/1000000 [06:48<3070:26:21, 11.05s/it, loss=0.0557, lr=0.002, norm_target=9.76]Steps:   0%|          | 36/1000000 [06:48<3065:43:58, 11.04s/it, loss=0.0557, lr=0.002, norm_target=9.76]Steps:   0%|          | 36/1000000 [06:59<3065:43:58, 11.04s/it, loss=0.0109, lr=0.002, norm_target=9.76]Steps:   0%|          | 37/1000000 [06:59<3063:04:11, 11.03s/it, loss=0.0109, lr=0.002, norm_target=9.76]Steps:   0%|          | 37/1000000 [07:10<3063:04:11, 11.03s/it, loss=0.049, lr=0.002, norm_target=9.76] Steps:   0%|          | 38/1000000 [07:10<3061:39:15, 11.02s/it, loss=0.049, lr=0.002, norm_target=9.76]Steps:   0%|          | 38/1000000 [07:21<3061:39:15, 11.02s/it, loss=0.0204, lr=0.002, norm_target=9.76]Steps:   0%|          | 39/1000000 [07:21<3059:51:57, 11.02s/it, loss=0.0204, lr=0.002, norm_target=9.76]Steps:   0%|          | 39/1000000 [07:32<3059:51:57, 11.02s/it, loss=0.0306, lr=0.002, norm_target=9.89]Steps:   0%|          | 40/1000000 [07:32<3059:43:10, 11.02s/it, loss=0.0306, lr=0.002, norm_target=9.89]Steps:   0%|          | 40/1000000 [07:43<3059:43:10, 11.02s/it, loss=0.0061, lr=0.002, norm_target=9.89]Steps:   0%|          | 41/1000000 [07:43<3058:28:22, 11.01s/it, loss=0.0061, lr=0.002, norm_target=9.89]Steps:   0%|          | 41/1000000 [07:54<3058:28:22, 11.01s/it, loss=0.0725, lr=0.002, norm_target=9.89]Steps:   0%|          | 42/1000000 [07:54<3060:40:44, 11.02s/it, loss=0.0725, lr=0.002, norm_target=9.89]Steps:   0%|          | 42/1000000 [08:05<3060:40:44, 11.02s/it, loss=0.334, lr=0.002, norm_target=9.89] Steps:   0%|          | 43/1000000 [08:05<3062:37:21, 11.03s/it, loss=0.334, lr=0.002, norm_target=9.89]Steps:   0%|          | 43/1000000 [08:16<3062:37:21, 11.03s/it, loss=0.00402, lr=0.002, norm_target=10]Steps:   0%|          | 44/1000000 [08:16<3062:01:58, 11.02s/it, loss=0.00402, lr=0.002, norm_target=10]Steps:   0%|          | 44/1000000 [08:27<3062:01:58, 11.02s/it, loss=0.0154, lr=0.002, norm_target=10] Steps:   0%|          | 45/1000000 [08:27<3061:25:33, 11.02s/it, loss=0.0154, lr=0.002, norm_target=10]Steps:   0%|          | 45/1000000 [08:38<3061:25:33, 11.02s/it, loss=0.00448, lr=0.002, norm_target=10]Steps:   0%|          | 46/1000000 [08:38<3060:24:47, 11.02s/it, loss=0.00448, lr=0.002, norm_target=10]Steps:   0%|          | 46/1000000 [08:49<3060:24:47, 11.02s/it, loss=0.00738, lr=0.002, norm_target=10]Steps:   0%|          | 47/1000000 [08:49<3059:47:29, 11.02s/it, loss=0.00738, lr=0.002, norm_target=10]Steps:   0%|          | 47/1000000 [09:00<3059:47:29, 11.02s/it, loss=0.458, lr=0.002, norm_target=10.2]Steps:   0%|          | 48/1000000 [09:00<3058:52:27, 11.01s/it, loss=0.458, lr=0.002, norm_target=10.2]Steps:   0%|          | 48/1000000 [09:11<3058:52:27, 11.01s/it, loss=0.00227, lr=0.002, norm_target=10.2]Steps:   0%|          | 49/1000000 [09:11<3058:09:06, 11.01s/it, loss=0.00227, lr=0.002, norm_target=10.2]Steps:   0%|          | 49/1000000 [09:22<3058:09:06, 11.01s/it, loss=0.00379, lr=0.002, norm_target=10.2]Steps:   0%|          | 50/1000000 [09:22<3057:59:40, 11.01s/it, loss=0.00379, lr=0.002, norm_target=10.2]Steps:   0%|          | 50/1000000 [09:33<3057:59:40, 11.01s/it, loss=0.00946, lr=0.002, norm_target=10.2]Steps:   0%|          | 51/1000000 [09:33<3057:12:46, 11.01s/it, loss=0.00946, lr=0.002, norm_target=10.2]Steps:   0%|          | 51/1000000 [09:44<3057:12:46, 11.01s/it, loss=0.459, lr=0.002, norm_target=10.3]  Steps:   0%|          | 52/1000000 [09:44<3056:37:34, 11.00s/it, loss=0.459, lr=0.002, norm_target=10.3]Steps:   0%|          | 52/1000000 [09:55<3056:37:34, 11.00s/it, loss=0.00192, lr=0.002, norm_target=10.3]Steps:   0%|          | 53/1000000 [09:55<3055:16:00, 11.00s/it, loss=0.00192, lr=0.002, norm_target=10.3]Steps:   0%|          | 53/1000000 [10:06<3055:16:00, 11.00s/it, loss=0.00464, lr=0.002, norm_target=10.3]Steps:   0%|          | 54/1000000 [10:06<3054:53:08, 11.00s/it, loss=0.00464, lr=0.002, norm_target=10.3]Steps:   0%|          | 54/1000000 [10:17<3054:53:08, 11.00s/it, loss=0.0526, lr=0.002, norm_target=10.3] Steps:   0%|          | 55/1000000 [10:17<3054:45:54, 11.00s/it, loss=0.0526, lr=0.002, norm_target=10.3]