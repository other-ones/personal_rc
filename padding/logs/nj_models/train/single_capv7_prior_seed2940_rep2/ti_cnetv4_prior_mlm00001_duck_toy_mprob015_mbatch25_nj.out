INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'sample_max_value', 'variance_type', 'thresholding', 'prediction_type', 'timestep_spacing', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'num_attention_heads', 'addition_embed_type', 'time_embedding_type', 'class_embeddings_concat', 'projection_class_embeddings_input_dim', 'encoder_hid_dim', 'use_linear_projection', 'addition_embed_type_num_heads', 'transformer_layers_per_block', 'num_class_embeds', 'mid_block_only_cross_attention', 'cross_attention_norm', 'addition_time_embed_dim', 'resnet_skip_time_act', 'only_cross_attention', 'time_embedding_act_fn', 'upcast_attention', 'time_cond_proj_dim', 'encoder_hid_dim_type', 'timestep_post_act', 'resnet_out_scale_factor', 'conv_in_kernel', 'mid_block_type', 'class_embed_type', 'dual_cross_attention', 'time_embedding_dim', 'resnet_time_scale_shift', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:24<?, ?it/s, loss=0.27, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 1/1000000 [00:24<6711:43:07, 24.16s/it, loss=0.27, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 1/1000000 [00:42<6711:43:07, 24.16s/it, loss=0.397, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 2/1000000 [00:42<5804:54:07, 20.90s/it, loss=0.397, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 2/1000000 [01:01<5804:54:07, 20.90s/it, loss=0.0883, loss_mlm=0.892, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 3/1000000 [01:01<5519:54:23, 19.87s/it, loss=0.0883, loss_mlm=0.892, lr=0.004, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 3/1000000 [01:19<5519:54:23, 19.87s/it, loss=0.00677, loss_mlm=0.788, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 4/1000000 [01:19<5373:53:55, 19.35s/it, loss=0.00677, loss_mlm=0.788, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 4/1000000 [01:38<5373:53:55, 19.35s/it, loss=0.0232, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=8.87]  Steps:   0%|          | 5/1000000 [01:38<5288:29:13, 19.04s/it, loss=0.0232, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 5/1000000 [01:49<5288:29:13, 19.04s/it, loss=0.0969, loss_mlm=0.842, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 6/1000000 [01:49<4558:51:45, 16.41s/it, loss=0.0969, loss_mlm=0.842, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 6/1000000 [02:01<4558:51:45, 16.41s/it, loss=0.168, loss_mlm=0.972, lr=0.004, norm_mask=8.02, norm_target=8.87] Steps:   0%|          | 7/1000000 [02:01<4097:32:00, 14.75s/it, loss=0.168, loss_mlm=0.972, lr=0.004, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 7/1000000 [02:12<4097:32:00, 14.75s/it, loss=0.0727, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 8/1000000 [02:12<3792:42:47, 13.65s/it, loss=0.0727, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 8/1000000 [02:23<3792:42:47, 13.65s/it, loss=0.219, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=9.33] Steps:   0%|          | 9/1000000 [02:23<3588:24:51, 12.92s/it, loss=0.219, loss_mlm=1.19, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 9/1000000 [02:35<3588:24:51, 12.92s/it, loss=0.119, loss_mlm=0.803, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 10/1000000 [02:35<3451:50:29, 12.43s/it, loss=0.119, loss_mlm=0.803, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 10/1000000 [02:46<3451:50:29, 12.43s/it, loss=0.0332, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 11/1000000 [02:46<3356:09:21, 12.08s/it, loss=0.0332, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=9.33]Steps:   0%|          | 11/1000000 [02:57<3356:09:21, 12.08s/it, loss=0.171, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=9.86] Steps:   0%|          | 12/1000000 [02:57<3291:38:11, 11.85s/it, loss=0.171, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 12/1000000 [03:08<3291:38:11, 11.85s/it, loss=0.0846, loss_mlm=0.962, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 13/1000000 [03:08<3246:03:47, 11.69s/it, loss=0.0846, loss_mlm=0.962, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 13/1000000 [03:20<3246:03:47, 11.69s/it, loss=0.161, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=9.86]  Steps:   0%|          | 14/1000000 [03:20<3213:55:24, 11.57s/it, loss=0.161, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 14/1000000 [03:31<3213:55:24, 11.57s/it, loss=0.0353, loss_mlm=0.802, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 15/1000000 [03:31<3191:22:54, 11.49s/it, loss=0.0353, loss_mlm=0.802, lr=0.004, norm_mask=8.02, norm_target=9.86]Steps:   0%|          | 15/1000000 [03:42<3191:22:54, 11.49s/it, loss=0.251, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.4]  Steps:   0%|          | 16/1000000 [03:42<3175:52:13, 11.43s/it, loss=0.251, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 16/1000000 [03:54<3175:52:13, 11.43s/it, loss=0.0128, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 17/1000000 [03:54<3195:14:21, 11.50s/it, loss=0.0128, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 17/1000000 [04:05<3195:14:21, 11.50s/it, loss=0.32, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=10.4]   Steps:   0%|          | 18/1000000 [04:05<3178:05:49, 11.44s/it, loss=0.32, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 18/1000000 [04:17<3178:05:49, 11.44s/it, loss=0.00955, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 19/1000000 [04:17<3166:47:41, 11.40s/it, loss=0.00955, loss_mlm=1.24, lr=0.004, norm_mask=8.02, norm_target=10.4]Steps:   0%|          | 19/1000000 [04:28<3166:47:41, 11.40s/it, loss=0.00281, loss_mlm=0.791, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 20/1000000 [04:28<3159:05:38, 11.37s/it, loss=0.00281, loss_mlm=0.791, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 20/1000000 [04:39<3159:05:38, 11.37s/it, loss=0.0937, loss_mlm=0.944, lr=0.004, norm_mask=8.02, norm_target=10.9] Steps:   0%|          | 21/1000000 [04:39<3153:38:51, 11.35s/it, loss=0.0937, loss_mlm=0.944, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 21/1000000 [04:51<3153:38:51, 11.35s/it, loss=0.178, loss_mlm=0.902, lr=0.004, norm_mask=8.02, norm_target=10.9] Steps:   0%|          | 22/1000000 [04:51<3150:07:54, 11.34s/it, loss=0.178, loss_mlm=0.902, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 22/1000000 [05:02<3150:07:54, 11.34s/it, loss=0.0837, loss_mlm=0.772, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 23/1000000 [05:02<3147:55:38, 11.33s/it, loss=0.0837, loss_mlm=0.772, lr=0.004, norm_mask=8.02, norm_target=10.9]Steps:   0%|          | 23/1000000 [05:13<3147:55:38, 11.33s/it, loss=0.149, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=11.4] Steps:   0%|          | 24/1000000 [05:13<3146:36:29, 11.33s/it, loss=0.149, loss_mlm=0.858, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 24/1000000 [05:25<3146:36:29, 11.33s/it, loss=0.0835, loss_mlm=0.8, lr=0.004, norm_mask=8.02, norm_target=11.4] Steps:   0%|          | 25/1000000 [05:25<3144:45:30, 11.32s/it, loss=0.0835, loss_mlm=0.8, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 25/1000000 [05:36<3144:45:30, 11.32s/it, loss=0.138, loss_mlm=1.13, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 26/1000000 [05:36<3142:47:20, 11.31s/it, loss=0.138, loss_mlm=1.13, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 26/1000000 [05:47<3142:47:20, 11.31s/it, loss=0.0407, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 27/1000000 [05:47<3141:21:48, 11.31s/it, loss=0.0407, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=11.4]Steps:   0%|          | 27/1000000 [05:58<3141:21:48, 11.31s/it, loss=0.168, loss_mlm=0.627, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 28/1000000 [05:58<3141:16:45, 11.31s/it, loss=0.168, loss_mlm=0.627, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 28/1000000 [06:10<3141:16:45, 11.31s/it, loss=0.152, loss_mlm=0.755, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 29/1000000 [06:10<3141:44:33, 11.31s/it, loss=0.152, loss_mlm=0.755, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 29/1000000 [06:21<3141:44:33, 11.31s/it, loss=0.121, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=11.8] Steps:   0%|          | 30/1000000 [06:21<3140:34:41, 11.31s/it, loss=0.121, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 30/1000000 [06:32<3140:34:41, 11.31s/it, loss=0.215, loss_mlm=1.09, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 31/1000000 [06:32<3140:38:18, 11.31s/it, loss=0.215, loss_mlm=1.09, lr=0.004, norm_mask=8.02, norm_target=11.8]Steps:   0%|          | 31/1000000 [06:44<3140:38:18, 11.31s/it, loss=0.114, loss_mlm=0.648, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 32/1000000 [06:44<3140:43:22, 11.31s/it, loss=0.114, loss_mlm=0.648, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 32/1000000 [06:55<3140:43:22, 11.31s/it, loss=0.147, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=12.2] Steps:   0%|          | 33/1000000 [06:55<3140:18:51, 11.31s/it, loss=0.147, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 33/1000000 [07:06<3140:18:51, 11.31s/it, loss=0.112, loss_mlm=0.931, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 34/1000000 [07:06<3140:08:14, 11.30s/it, loss=0.112, loss_mlm=0.931, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 34/1000000 [07:18<3140:08:14, 11.30s/it, loss=0.0214, loss_mlm=0.754, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 35/1000000 [07:18<3140:06:37, 11.30s/it, loss=0.0214, loss_mlm=0.754, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 35/1000000 [07:29<3140:06:37, 11.30s/it, loss=0.0845, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=12.6] Steps:   0%|          | 36/1000000 [07:29<3140:14:44, 11.31s/it, loss=0.0845, loss_mlm=1.18, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 36/1000000 [07:40<3140:14:44, 11.31s/it, loss=0.0134, loss_mlm=0.83, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 37/1000000 [07:40<3140:27:42, 11.31s/it, loss=0.0134, loss_mlm=0.83, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 37/1000000 [07:52<3140:27:42, 11.31s/it, loss=0.151, loss_mlm=0.934, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 38/1000000 [07:52<3168:03:17, 11.41s/it, loss=0.151, loss_mlm=0.934, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 38/1000000 [08:03<3168:03:17, 11.41s/it, loss=0.0134, loss_mlm=0.935, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 39/1000000 [08:03<3160:30:41, 11.38s/it, loss=0.0134, loss_mlm=0.935, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 39/1000000 [08:14<3160:30:41, 11.38s/it, loss=0.0723, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=12.9] Steps:   0%|          | 40/1000000 [08:14<3154:26:52, 11.36s/it, loss=0.0723, loss_mlm=1.25, lr=0.004, norm_mask=8.02, norm_target=12.9]Steps:   0%|          | 40/1000000 [08:26<3154:26:52, 11.36s/it, loss=0.0259, loss_mlm=0.8, lr=0.004, norm_mask=8.02, norm_target=12.9] Steps:   0%|          | 41/1000000 [08:26<3150:21:46, 11.34s/it, loss=0.0259, loss_mlm=0.8, lr=0.004, norm_mask=8.02, norm_target=12.9]Steps:   0%|          | 41/1000000 [08:37<3150:21:46, 11.34s/it, loss=0.0493, loss_mlm=0.958, lr=0.004, norm_mask=8.02, norm_target=12.9]Steps:   0%|          | 42/1000000 [08:37<3146:29:07, 11.33s/it, loss=0.0493, loss_mlm=0.958, lr=0.004, norm_mask=8.02, norm_target=12.9]Steps:   0%|          | 42/1000000 [08:48<3146:29:07, 11.33s/it, loss=0.183, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=12.9]  Steps:   0%|          | 43/1000000 [08:48<3145:23:29, 11.32s/it, loss=0.183, loss_mlm=1.02, lr=0.004, norm_mask=8.02, norm_target=12.9]Steps:   0%|          | 43/1000000 [09:00<3145:23:29, 11.32s/it, loss=0.226, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 44/1000000 [09:00<3144:10:02, 11.32s/it, loss=0.226, loss_mlm=1.04, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 44/1000000 [09:11<3144:10:02, 11.32s/it, loss=0.0896, loss_mlm=0.912, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 45/1000000 [09:11<3142:52:59, 11.31s/it, loss=0.0896, loss_mlm=0.912, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 45/1000000 [09:22<3142:52:59, 11.31s/it, loss=0.022, loss_mlm=0.635, lr=0.004, norm_mask=8.02, norm_target=13.3] Steps:   0%|          | 46/1000000 [09:22<3142:17:00, 11.31s/it, loss=0.022, loss_mlm=0.635, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 46/1000000 [09:34<3142:17:00, 11.31s/it, loss=0.175, loss_mlm=0.873, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 47/1000000 [09:34<3141:52:26, 11.31s/it, loss=0.175, loss_mlm=0.873, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 47/1000000 [09:45<3141:52:26, 11.31s/it, loss=0.257, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=13.6]  Steps:   0%|          | 48/1000000 [09:45<3140:42:28, 11.31s/it, loss=0.257, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 48/1000000 [09:56<3140:42:28, 11.31s/it, loss=0.00579, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 49/1000000 [09:56<3140:40:47, 11.31s/it, loss=0.00579, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 49/1000000 [10:07<3140:40:47, 11.31s/it, loss=0.00819, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 50/1000000 [10:07<3140:23:51, 11.31s/it, loss=0.00819, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 50/1000000 [10:19<3140:23:51, 11.31s/it, loss=0.0156, loss_mlm=0.91, lr=0.004, norm_mask=8.02, norm_target=13.6] Steps:   0%|          | 51/1000000 [10:19<3140:17:09, 11.31s/it, loss=0.0156, loss_mlm=0.91, lr=0.004, norm_mask=8.02, norm_target=13.6]Steps:   0%|          | 51/1000000 [10:30<3140:17:09, 11.31s/it, loss=0.297, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14]    Steps:   0%|          | 52/1000000 [10:30<3142:42:26, 11.31s/it, loss=0.297, loss_mlm=1.2, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 52/1000000 [10:41<3142:42:26, 11.31s/it, loss=0.103, loss_mlm=1.31, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 53/1000000 [10:41<3143:17:22, 11.32s/it, loss=0.103, loss_mlm=1.31, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 53/1000000 [10:53<3143:17:22, 11.32s/it, loss=0.0707, loss_mlm=0.85, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 54/1000000 [10:53<3143:13:56, 11.32s/it, loss=0.0707, loss_mlm=0.85, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 54/1000000 [11:04<3143:13:56, 11.32s/it, loss=0.167, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=14]    Steps:   0%|          | 55/1000000 [11:04<3143:18:16, 11.32s/it, loss=0.167, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 55/1000000 [11:15<3143:18:16, 11.32s/it, loss=0.257, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 56/1000000 [11:15<3142:44:50, 11.31s/it, loss=0.257, loss_mlm=1.1, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 56/1000000 [11:27<3142:44:50, 11.31s/it, loss=0.275, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 57/1000000 [11:27<3143:10:07, 11.32s/it, loss=0.275, loss_mlm=1.05, lr=0.004, norm_mask=8.02, norm_target=14.3]