INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'prediction_type', 'dynamic_thresholding_ratio', 'timestep_spacing', 'thresholding', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'num_attention_heads', 'only_cross_attention', 'time_cond_proj_dim', 'cross_attention_norm', 'timestep_post_act', 'time_embedding_type', 'addition_embed_type_num_heads', 'mid_block_type', 'transformer_layers_per_block', 'conv_in_kernel', 'use_linear_projection', 'addition_embed_type', 'mid_block_only_cross_attention', 'resnet_time_scale_shift', 'encoder_hid_dim_type', 'conv_out_kernel', 'resnet_skip_time_act', 'time_embedding_dim', 'dual_cross_attention', 'upcast_attention', 'class_embed_type', 'addition_time_embed_dim', 'projection_class_embeddings_input_dim', 'class_embeddings_concat', 'num_class_embeds', 'encoder_hid_dim', 'resnet_out_scale_factor', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
saved_models/nj_models/single_capv7_prior_seed2940_rep2/duck_toy/ti_cnetv4_prior_mlm00001_duck_toy_mprob015_mbatch25_nj/src/command.txt command_path
nj_train.py item
--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 item
--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/duck_toy item
--learnable_property=object item
--placeholder_token1=<duck_toy> item
--train_prior_concept1=duck item
--eval_prior_concept1=duck toy item
--resolution=512 item
--train_batch_size=1 item
--gradient_accumulation_steps=4 item
--learning_rate=5e-4 item
--lr_scheduler=constant item
--normalize_mask_embeds=0 item
--lr_warmup_steps=0 item
--output_dir=saved_models/nj_models/single_capv7_prior_seed2940_rep2/duck_toy item
--seed=2940 item
--mask_tokens=[MASK] item
--lambda_mlm=0.0001 item
--freeze_mask_embedding=1 item
--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt item
--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt item
--mask_prob=0.15 item
--mlm_target=masked item
--mlm_batch_size=25 item
--scale_lr item
--eval_prompt_type=nonliving item
--train_prompt_type=nonliving item
--silent=0 item
--rev=0 item
--normalize_target1=0 item
--caption_root=../datasets_pkgs/captions/v7 item
--run_name=ti_cnetv4_prior_mlm00001_duck_toy_mprob015_mbatch25_nj item
--include_prior_concept=1 item
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
seeded
captions_nonliving_relations	29376
captions_nonliving_styles	378
captions_nonliving_human_interactions	4176
captions_nonliving_backgrounds	552
captions_nonliving_creatives	117
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
INFO:__main__:STEP 0 Running validation... 
 Generating 8 images with prompt: ['a <duck_toy> duck in the jungle', 'a <duck_toy> duck with a city in the background', 'a <duck_toy> duck with a mountain in the background', 'a <duck_toy> duck with the Eiffel Tower in the background', 'a <duck_toy> duck floating on top of water', 'a <duck_toy> duck floating in an ocean of milk', 'a <duck_toy> duck on top of the sidewalk in a crowded street', 'a cube shaped <duck_toy> duck'].


----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
Step		|0
Raw		|vincent    van        gogh       is         M[auc]     tioning    <duck_toy> duck      
Masked		|vincent    van        gogh       is         [MASK]     tioning    <duck_toy> duck      
Preds		|an         hand       gogh       is         M[ni]      ating      duck       duck      
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------


  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|▍         | 1/25 [00:00<00:09,  2.54it/s][A
  8%|▊         | 2/25 [00:00<00:08,  2.74it/s][A
 12%|█▏        | 3/25 [00:01<00:07,  2.80it/s][A
 16%|█▌        | 4/25 [00:01<00:07,  2.83it/s][A
 20%|██        | 5/25 [00:01<00:07,  2.85it/s][A
 24%|██▍       | 6/25 [00:02<00:06,  2.86it/s][A
 28%|██▊       | 7/25 [00:02<00:06,  2.87it/s][A
 32%|███▏      | 8/25 [00:02<00:05,  2.87it/s][A
 36%|███▌      | 9/25 [00:03<00:05,  2.87it/s][A
 40%|████      | 10/25 [00:03<00:05,  2.87it/s][A
 44%|████▍     | 11/25 [00:03<00:04,  2.87it/s][A
 48%|████▊     | 12/25 [00:04<00:04,  2.87it/s][A
 52%|█████▏    | 13/25 [00:04<00:04,  2.87it/s][A
 56%|█████▌    | 14/25 [00:04<00:03,  2.87it/s][A
 60%|██████    | 15/25 [00:05<00:03,  2.87it/s][A
 64%|██████▍   | 16/25 [00:05<00:03,  2.87it/s][A
 68%|██████▊   | 17/25 [00:05<00:02,  2.87it/s][A
 72%|███████▏  | 18/25 [00:06<00:02,  2.87it/s][A
 76%|███████▌  | 19/25 [00:06<00:02,  2.87it/s][A
 80%|████████  | 20/25 [00:07<00:01,  2.87it/s][A
 84%|████████▍ | 21/25 [00:07<00:01,  2.87it/s][A
 88%|████████▊ | 22/25 [00:07<00:01,  2.87it/s][A
 92%|█████████▏| 23/25 [00:08<00:00,  2.87it/s][A
 96%|█████████▌| 24/25 [00:08<00:00,  2.87it/s][A
100%|██████████| 25/25 [00:08<00:00,  2.87it/s][A100%|██████████| 25/25 [00:09<00:00,  2.60it/s]
Steps:   0%|          | 0/1000000 [00:24<?, ?it/s, loss=0.197, loss_mlm=1.05, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 1/1000000 [00:24<6714:21:10, 24.17s/it, loss=0.197, loss_mlm=1.05, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 1/1000000 [00:35<6714:21:10, 24.17s/it, loss=0.694, loss_mlm=1.16, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 2/1000000 [00:35<4623:42:04, 16.65s/it, loss=0.694, loss_mlm=1.16, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 2/1000000 [00:46<4623:42:04, 16.65s/it, loss=0.121, loss_mlm=0.892, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 3/1000000 [00:46<3934:58:11, 14.17s/it, loss=0.121, loss_mlm=0.892, lr=0.002, norm_mask=8.02, norm_target=8.62]Steps:   0%|          | 3/1000000 [00:58<3934:58:11, 14.17s/it, loss=0.00387, loss_mlm=0.788, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 4/1000000 [00:58<3615:49:14, 13.02s/it, loss=0.00387, loss_mlm=0.788, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 4/1000000 [01:09<3615:49:14, 13.02s/it, loss=0.00541, loss_mlm=1.29, lr=0.002, norm_mask=8.02, norm_target=8.71] Steps:   0%|          | 5/1000000 [01:09<3436:47:45, 12.37s/it, loss=0.00541, loss_mlm=1.29, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 5/1000000 [01:20<3436:47:45, 12.37s/it, loss=0.005, loss_mlm=0.831, lr=0.002, norm_mask=8.02, norm_target=8.71] Steps:   0%|          | 6/1000000 [01:20<3328:14:01, 11.98s/it, loss=0.005, loss_mlm=0.831, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 6/1000000 [01:31<3328:14:01, 11.98s/it, loss=0.0336, loss_mlm=0.977, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 7/1000000 [01:31<3258:40:53, 11.73s/it, loss=0.0336, loss_mlm=0.977, lr=0.002, norm_mask=8.02, norm_target=8.71]Steps:   0%|          | 7/1000000 [01:42<3258:40:53, 11.73s/it, loss=0.26, loss_mlm=1.03, lr=0.002, norm_mask=8.02, norm_target=8.87]   Steps:   0%|          | 8/1000000 [01:42<3213:00:09, 11.57s/it, loss=0.26, loss_mlm=1.03, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 8/1000000 [01:54<3213:00:09, 11.57s/it, loss=0.232, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 9/1000000 [01:54<3182:04:36, 11.46s/it, loss=0.232, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 9/1000000 [02:05<3182:04:36, 11.46s/it, loss=0.259, loss_mlm=0.777, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 10/1000000 [02:05<3161:43:51, 11.38s/it, loss=0.259, loss_mlm=0.777, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 10/1000000 [02:16<3161:43:51, 11.38s/it, loss=0.019, loss_mlm=1.16, lr=0.002, norm_mask=8.02, norm_target=8.87] Steps:   0%|          | 11/1000000 [02:16<3148:02:58, 11.33s/it, loss=0.019, loss_mlm=1.16, lr=0.002, norm_mask=8.02, norm_target=8.87]Steps:   0%|          | 11/1000000 [02:27<3148:02:58, 11.33s/it, loss=0.289, loss_mlm=1.07, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 12/1000000 [02:27<3137:45:21, 11.30s/it, loss=0.289, loss_mlm=1.07, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 12/1000000 [02:38<3137:45:21, 11.30s/it, loss=0.141, loss_mlm=0.94, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 13/1000000 [02:38<3130:56:51, 11.27s/it, loss=0.141, loss_mlm=0.94, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 13/1000000 [02:50<3130:56:51, 11.27s/it, loss=0.105, loss_mlm=1.26, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 14/1000000 [02:50<3126:59:32, 11.26s/it, loss=0.105, loss_mlm=1.26, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 14/1000000 [03:01<3126:59:32, 11.26s/it, loss=0.0132, loss_mlm=0.784, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 15/1000000 [03:01<3123:33:11, 11.24s/it, loss=0.0132, loss_mlm=0.784, lr=0.002, norm_mask=8.02, norm_target=9.03]Steps:   0%|          | 15/1000000 [03:12<3123:33:11, 11.24s/it, loss=0.0146, loss_mlm=1.24, lr=0.002, norm_mask=8.02, norm_target=9.22] Steps:   0%|          | 16/1000000 [03:12<3121:53:32, 11.24s/it, loss=0.0146, loss_mlm=1.24, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 16/1000000 [03:23<3121:53:32, 11.24s/it, loss=0.0202, loss_mlm=0.853, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 17/1000000 [03:23<3119:47:27, 11.23s/it, loss=0.0202, loss_mlm=0.853, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 17/1000000 [03:35<3119:47:27, 11.23s/it, loss=0.246, loss_mlm=1.13, lr=0.002, norm_mask=8.02, norm_target=9.22]  Steps:   0%|          | 18/1000000 [03:35<3118:16:04, 11.23s/it, loss=0.246, loss_mlm=1.13, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 18/1000000 [03:46<3118:16:04, 11.23s/it, loss=0.0149, loss_mlm=1.26, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 19/1000000 [03:46<3141:18:45, 11.31s/it, loss=0.0149, loss_mlm=1.26, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 19/1000000 [03:57<3141:18:45, 11.31s/it, loss=0.00289, loss_mlm=0.784, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 20/1000000 [03:57<3134:05:52, 11.28s/it, loss=0.00289, loss_mlm=0.784, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 20/1000000 [04:09<3134:05:52, 11.28s/it, loss=0.0984, loss_mlm=0.928, lr=0.002, norm_mask=8.02, norm_target=9.4] Steps:   0%|          | 21/1000000 [04:09<3128:28:08, 11.26s/it, loss=0.0984, loss_mlm=0.928, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 21/1000000 [04:20<3128:28:08, 11.26s/it, loss=0.305, loss_mlm=0.898, lr=0.002, norm_mask=8.02, norm_target=9.4] Steps:   0%|          | 22/1000000 [04:20<3124:08:03, 11.25s/it, loss=0.305, loss_mlm=0.898, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 22/1000000 [04:31<3124:08:03, 11.25s/it, loss=0.0936, loss_mlm=0.763, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 23/1000000 [04:31<3121:02:27, 11.24s/it, loss=0.0936, loss_mlm=0.763, lr=0.002, norm_mask=8.02, norm_target=9.4]Steps:   0%|          | 23/1000000 [04:42<3121:02:27, 11.24s/it, loss=0.107, loss_mlm=0.859, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 24/1000000 [04:42<3120:52:08, 11.24s/it, loss=0.107, loss_mlm=0.859, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 24/1000000 [04:53<3120:52:08, 11.24s/it, loss=0.154, loss_mlm=0.814, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 25/1000000 [04:53<3119:42:00, 11.23s/it, loss=0.154, loss_mlm=0.814, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 25/1000000 [05:05<3119:42:00, 11.23s/it, loss=0.0169, loss_mlm=1.15, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 26/1000000 [05:05<3118:59:19, 11.23s/it, loss=0.0169, loss_mlm=1.15, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 26/1000000 [05:16<3118:59:19, 11.23s/it, loss=0.0215, loss_mlm=1.07, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 27/1000000 [05:16<3118:13:20, 11.23s/it, loss=0.0215, loss_mlm=1.07, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 27/1000000 [05:27<3118:13:20, 11.23s/it, loss=0.0197, loss_mlm=0.642, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 28/1000000 [05:27<3117:41:32, 11.22s/it, loss=0.0197, loss_mlm=0.642, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 28/1000000 [05:38<3117:41:32, 11.22s/it, loss=0.321, loss_mlm=0.756, lr=0.002, norm_mask=8.02, norm_target=9.69] Steps:   0%|          | 29/1000000 [05:38<3117:02:03, 11.22s/it, loss=0.321, loss_mlm=0.756, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 29/1000000 [05:50<3117:02:03, 11.22s/it, loss=0.147, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=9.69] Steps:   0%|          | 30/1000000 [05:50<3119:00:59, 11.23s/it, loss=0.147, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 30/1000000 [06:01<3119:00:59, 11.23s/it, loss=0.355, loss_mlm=1.13, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 31/1000000 [06:01<3119:55:17, 11.23s/it, loss=0.355, loss_mlm=1.13, lr=0.002, norm_mask=8.02, norm_target=9.69]Steps:   0%|          | 31/1000000 [06:12<3119:55:17, 11.23s/it, loss=0.127, loss_mlm=0.645, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 32/1000000 [06:12<3118:30:33, 11.23s/it, loss=0.127, loss_mlm=0.645, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 32/1000000 [06:23<3118:30:33, 11.23s/it, loss=0.288, loss_mlm=1.25, lr=0.002, norm_mask=8.02, norm_target=9.82] Steps:   0%|          | 33/1000000 [06:23<3117:45:45, 11.22s/it, loss=0.288, loss_mlm=1.25, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 33/1000000 [06:34<3117:45:45, 11.22s/it, loss=0.068, loss_mlm=0.923, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 34/1000000 [06:34<3116:58:43, 11.22s/it, loss=0.068, loss_mlm=0.923, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 34/1000000 [06:46<3116:58:43, 11.22s/it, loss=0.0374, loss_mlm=0.751, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 35/1000000 [06:46<3116:48:13, 11.22s/it, loss=0.0374, loss_mlm=0.751, lr=0.002, norm_mask=8.02, norm_target=9.82]Steps:   0%|          | 35/1000000 [06:57<3116:48:13, 11.22s/it, loss=0.0871, loss_mlm=1.18, lr=0.002, norm_mask=8.02, norm_target=9.95] Steps:   0%|          | 36/1000000 [06:57<3116:58:18, 11.22s/it, loss=0.0871, loss_mlm=1.18, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 36/1000000 [07:08<3116:58:18, 11.22s/it, loss=0.00874, loss_mlm=0.815, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 37/1000000 [07:08<3116:30:45, 11.22s/it, loss=0.00874, loss_mlm=0.815, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 37/1000000 [07:19<3116:30:45, 11.22s/it, loss=0.0344, loss_mlm=0.952, lr=0.002, norm_mask=8.02, norm_target=9.95] Steps:   0%|          | 38/1000000 [07:19<3116:01:55, 11.22s/it, loss=0.0344, loss_mlm=0.952, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 38/1000000 [07:30<3116:01:55, 11.22s/it, loss=0.0133, loss_mlm=0.914, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 39/1000000 [07:30<3115:31:29, 11.22s/it, loss=0.0133, loss_mlm=0.914, lr=0.002, norm_mask=8.02, norm_target=9.95]Steps:   0%|          | 39/1000000 [07:42<3115:31:29, 11.22s/it, loss=0.0485, loss_mlm=1.27, lr=0.002, norm_mask=8.02, norm_target=10.1] Steps:   0%|          | 40/1000000 [07:42<3143:07:04, 11.32s/it, loss=0.0485, loss_mlm=1.27, lr=0.002, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 40/1000000 [07:53<3143:07:04, 11.32s/it, loss=0.00589, loss_mlm=0.788, lr=0.002, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 41/1000000 [07:53<3135:36:32, 11.29s/it, loss=0.00589, loss_mlm=0.788, lr=0.002, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 41/1000000 [08:04<3135:36:32, 11.29s/it, loss=0.0821, loss_mlm=0.942, lr=0.002, norm_mask=8.02, norm_target=10.1] Steps:   0%|          | 42/1000000 [08:04<3129:27:07, 11.27s/it, loss=0.0821, loss_mlm=0.942, lr=0.002, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 42/1000000 [08:16<3129:27:07, 11.27s/it, loss=0.446, loss_mlm=1, lr=0.002, norm_mask=8.02, norm_target=10.1]     Steps:   0%|          | 43/1000000 [08:16<3125:30:52, 11.25s/it, loss=0.446, loss_mlm=1, lr=0.002, norm_mask=8.02, norm_target=10.1]Steps:   0%|          | 43/1000000 [08:27<3125:30:52, 11.25s/it, loss=0.00389, loss_mlm=1.02, lr=0.002, norm_mask=8.02, norm_target=10.2]Steps:   0%|          | 44/1000000 [08:27<3122:45:08, 11.24s/it, loss=0.00389, loss_mlm=1.02, lr=0.002, norm_mask=8.02, norm_target=10.2]Steps:   0%|          | 44/1000000 [08:38<3122:45:08, 11.24s/it, loss=0.0122, loss_mlm=0.92, lr=0.002, norm_mask=8.02, norm_target=10.2] Steps:   0%|          | 45/1000000 [08:38<3120:39:22, 11.23s/it, loss=0.0122, loss_mlm=0.92, lr=0.002, norm_mask=8.02, norm_target=10.2]