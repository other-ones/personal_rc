INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'thresholding', 'variance_type', 'dynamic_thresholding_ratio', 'sample_max_value', 'timestep_spacing', 'clip_sample_range', 'prediction_type'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'upcast_attention', 'class_embeddings_concat', 'transformer_layers_per_block', 'num_class_embeds', 'time_embedding_type', 'conv_out_kernel', 'projection_class_embeddings_input_dim', 'addition_time_embed_dim', 'addition_embed_type', 'time_embedding_act_fn', 'time_embedding_dim', 'num_attention_heads', 'mid_block_type', 'dual_cross_attention', 'conv_in_kernel', 'encoder_hid_dim', 'time_cond_proj_dim', 'resnet_time_scale_shift', 'class_embed_type', 'mid_block_only_cross_attention', 'addition_embed_type_num_heads', 'resnet_skip_time_act', 'resnet_out_scale_factor', 'encoder_hid_dim_type', 'use_linear_projection', 'cross_attention_norm', 'timestep_post_act', 'only_cross_attention'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
saved_models/nj_models/single_capv7_prior_seed2940_rep2/dog6/ti_cnetv4_prior_mlm0001_dog6_mprob015_mbatch25_nj/src/command.txt command_path
nj_train.py item
--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 item
--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/dog6 item
--learnable_property=object item
--placeholder_token1=<dog6> item
--train_prior_concept1=dog item
--eval_prior_concept1=dog item
--resolution=512 item
--train_batch_size=1 item
--gradient_accumulation_steps=4 item
--learning_rate=5e-4 item
--lr_scheduler=constant item
--normalize_mask_embeds=0 item
--lr_warmup_steps=0 item
--output_dir=saved_models/nj_models/single_capv7_prior_seed2940_rep2/dog6 item
--seed=2940 item
--mask_tokens=[MASK] item
--lambda_mlm=0.001 item
--freeze_mask_embedding=1 item
--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt item
--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt item
--mask_prob=0.15 item
--mlm_target=masked item
--mlm_batch_size=25 item
--scale_lr item
--eval_prompt_type=living item
--train_prompt_type=pet item
--silent=0 item
--rev=0 item
--normalize_target1=0 item
--caption_root=../datasets_pkgs/captions/v7 item
--run_name=ti_cnetv4_prior_mlm0001_dog6_mprob015_mbatch25_nj item
--include_prior_concept=1 item
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
INFO:__main__:STEP 0 Running validation... 
 Generating 7 images with prompt: ['a <dog6> dog in the jungle', 'a <dog6> dog with a city in the background', 'a <dog6> dog with a mountain in the background', 'a <dog6> dog on top of a purple rug in a forest', 'a <dog6> dog in a chef outfit', 'a <dog6> dog in a police outfit', 'a cube shaped <dog6> dog'].


----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
Step		|0
Raw		|a          close      -          up         photo      of         the        <dog6>     dog        at         las        vegas      strip     
Masked		|a          close      -          up         photo      of         the        <dog6>     dog        at         las        vegas      strip     
Preds		|a          close      -          up         photo      of         the        dog        dog        at         las        vegas      strip     
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------


  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|â–         | 1/25 [00:00<00:08,  2.70it/s][A
  8%|â–Š         | 2/25 [00:00<00:07,  3.01it/s][A
 12%|â–ˆâ–        | 3/25 [00:00<00:07,  3.12it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:01<00:06,  3.17it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:06,  3.20it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:01<00:05,  3.22it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:02<00:05,  3.23it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:02<00:05,  3.24it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:02<00:04,  3.24it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:03<00:04,  3.24it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:03<00:04,  3.25it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:03<00:04,  3.25it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:04<00:03,  3.25it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:04<00:03,  3.25it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:04<00:03,  3.25it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:04<00:02,  3.25it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:05<00:02,  3.25it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:05<00:02,  3.25it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:05<00:01,  3.25it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:06<00:01,  3.25it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:06<00:01,  3.25it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:06<00:00,  3.25it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:07<00:00,  3.25it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:07<00:00,  3.25it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:07<00:00,  3.24it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:08<00:00,  2.94it/s]
Steps:   0%|          | 0/1000000 [00:23<?, ?it/s, loss=0.123, loss_mlm=0.862, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:23<6439:22:55, 23.18s/it, loss=0.123, loss_mlm=0.862, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:34<6439:22:55, 23.18s/it, loss=0.517, loss_mlm=0.963, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:34<4512:12:11, 16.24s/it, loss=0.517, loss_mlm=0.963, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:45<4512:12:11, 16.24s/it, loss=0.064, loss_mlm=0.655, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:45<3871:53:06, 13.94s/it, loss=0.064, loss_mlm=0.655, lr=0.002, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:56<3871:53:06, 13.94s/it, loss=0.00387, loss_mlm=0.953, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 4/1000000 [00:56<3573:19:13, 12.86s/it, loss=0.00387, loss_mlm=0.953, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 4/1000000 [01:08<3573:19:13, 12.86s/it, loss=0.00355, loss_mlm=0.646, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 5/1000000 [01:08<3407:41:36, 12.27s/it, loss=0.00355, loss_mlm=0.646, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 5/1000000 [01:19<3407:41:36, 12.27s/it, loss=0.00635, loss_mlm=1.04, lr=0.002, norm_mask=8.02, norm_target=8.16] Steps:   0%|          | 6/1000000 [01:19<3307:53:40, 11.91s/it, loss=0.00635, loss_mlm=1.04, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 6/1000000 [01:30<3307:53:40, 11.91s/it, loss=0.0244, loss_mlm=0.928, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 7/1000000 [01:30<3243:38:34, 11.68s/it, loss=0.0244, loss_mlm=0.928, lr=0.002, norm_mask=8.02, norm_target=8.16]Steps:   0%|          | 7/1000000 [01:41<3243:38:34, 11.68s/it, loss=0.122, loss_mlm=0.569, lr=0.002, norm_mask=8.02, norm_target=8.24] Steps:   0%|          | 8/1000000 [01:41<3201:03:11, 11.52s/it, loss=0.122, loss_mlm=0.569, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 8/1000000 [01:52<3201:03:11, 11.52s/it, loss=0.142, loss_mlm=0.868, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 9/1000000 [01:52<3172:17:44, 11.42s/it, loss=0.142, loss_mlm=0.868, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 9/1000000 [02:04<3172:17:44, 11.42s/it, loss=0.121, loss_mlm=0.947, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 10/1000000 [02:04<3154:02:27, 11.35s/it, loss=0.121, loss_mlm=0.947, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 10/1000000 [02:15<3154:02:27, 11.35s/it, loss=0.0169, loss_mlm=0.565, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 11/1000000 [02:15<3140:08:24, 11.30s/it, loss=0.0169, loss_mlm=0.565, lr=0.002, norm_mask=8.02, norm_target=8.24]Steps:   0%|          | 11/1000000 [02:26<3140:08:24, 11.30s/it, loss=0.176, loss_mlm=1.08, lr=0.002, norm_mask=8.02, norm_target=8.33]  Steps:   0%|          | 12/1000000 [02:26<3131:46:56, 11.27s/it, loss=0.176, loss_mlm=1.08, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 12/1000000 [02:37<3131:46:56, 11.27s/it, loss=0.0853, loss_mlm=0.597, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 13/1000000 [02:37<3125:45:36, 11.25s/it, loss=0.0853, loss_mlm=0.597, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 13/1000000 [02:49<3125:45:36, 11.25s/it, loss=0.046, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=8.33]  Steps:   0%|          | 14/1000000 [02:49<3121:25:20, 11.24s/it, loss=0.046, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 14/1000000 [03:00<3121:25:20, 11.24s/it, loss=0.0128, loss_mlm=0.963, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 15/1000000 [03:00<3117:37:53, 11.22s/it, loss=0.0128, loss_mlm=0.963, lr=0.002, norm_mask=8.02, norm_target=8.33]Steps:   0%|          | 15/1000000 [03:11<3117:37:53, 11.22s/it, loss=0.00969, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 16/1000000 [03:11<3115:12:54, 11.21s/it, loss=0.00969, loss_mlm=1.12, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 16/1000000 [03:22<3115:12:54, 11.21s/it, loss=0.0122, loss_mlm=0.673, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 17/1000000 [03:22<3114:13:11, 11.21s/it, loss=0.0122, loss_mlm=0.673, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 17/1000000 [03:33<3114:13:11, 11.21s/it, loss=0.231, loss_mlm=1.09, lr=0.002, norm_mask=8.02, norm_target=8.43]  Steps:   0%|          | 18/1000000 [03:33<3113:51:41, 11.21s/it, loss=0.231, loss_mlm=1.09, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 18/1000000 [03:45<3113:51:41, 11.21s/it, loss=0.0118, loss_mlm=0.723, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 19/1000000 [03:45<3137:36:19, 11.30s/it, loss=0.0118, loss_mlm=0.723, lr=0.002, norm_mask=8.02, norm_target=8.43]Steps:   0%|          | 19/1000000 [03:56<3137:36:19, 11.30s/it, loss=0.00248, loss_mlm=0.673, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 20/1000000 [03:56<3129:09:31, 11.27s/it, loss=0.00248, loss_mlm=0.673, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 20/1000000 [04:07<3129:09:31, 11.27s/it, loss=0.0752, loss_mlm=1.03, lr=0.002, norm_mask=8.02, norm_target=8.59]  Steps:   0%|          | 21/1000000 [04:07<3123:31:54, 11.24s/it, loss=0.0752, loss_mlm=1.03, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 21/1000000 [04:18<3123:31:54, 11.24s/it, loss=0.163, loss_mlm=0.921, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 22/1000000 [04:18<3120:28:51, 11.23s/it, loss=0.163, loss_mlm=0.921, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 22/1000000 [04:30<3120:28:51, 11.23s/it, loss=0.041, loss_mlm=1.06, lr=0.002, norm_mask=8.02, norm_target=8.59] Steps:   0%|          | 23/1000000 [04:30<3117:33:37, 11.22s/it, loss=0.041, loss_mlm=1.06, lr=0.002, norm_mask=8.02, norm_target=8.59]Steps:   0%|          | 23/1000000 [04:41<3117:33:37, 11.22s/it, loss=0.081, loss_mlm=0.734, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 24/1000000 [04:41<3114:58:58, 11.21s/it, loss=0.081, loss_mlm=0.734, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 24/1000000 [04:52<3114:58:58, 11.21s/it, loss=0.0758, loss_mlm=0.816, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 25/1000000 [04:52<3114:40:32, 11.21s/it, loss=0.0758, loss_mlm=0.816, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 25/1000000 [05:03<3114:40:32, 11.21s/it, loss=0.0109, loss_mlm=0.789, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 26/1000000 [05:03<3113:36:20, 11.21s/it, loss=0.0109, loss_mlm=0.789, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 26/1000000 [05:14<3113:36:20, 11.21s/it, loss=0.0138, loss_mlm=0.967, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 27/1000000 [05:14<3111:56:33, 11.20s/it, loss=0.0138, loss_mlm=0.967, lr=0.002, norm_mask=8.02, norm_target=8.74]Steps:   0%|          | 27/1000000 [05:26<3111:56:33, 11.20s/it, loss=0.0119, loss_mlm=0.514, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 28/1000000 [05:26<3111:15:38, 11.20s/it, loss=0.0119, loss_mlm=0.514, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 28/1000000 [05:37<3111:15:38, 11.20s/it, loss=0.174, loss_mlm=1.15, lr=0.002, norm_mask=8.02, norm_target=8.89]  Steps:   0%|          | 29/1000000 [05:37<3111:07:46, 11.20s/it, loss=0.174, loss_mlm=1.15, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 29/1000000 [05:48<3111:07:46, 11.20s/it, loss=0.081, loss_mlm=0.757, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 30/1000000 [05:48<3110:41:44, 11.20s/it, loss=0.081, loss_mlm=0.757, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 30/1000000 [05:59<3110:41:44, 11.20s/it, loss=0.197, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=8.89] Steps:   0%|          | 31/1000000 [05:59<3109:59:39, 11.20s/it, loss=0.197, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=8.89]Steps:   0%|          | 31/1000000 [06:10<3109:59:39, 11.20s/it, loss=0.105, loss_mlm=0.697, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 32/1000000 [06:10<3111:06:19, 11.20s/it, loss=0.105, loss_mlm=0.697, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 32/1000000 [06:22<3111:06:19, 11.20s/it, loss=0.142, loss_mlm=0.981, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 33/1000000 [06:22<3111:03:25, 11.20s/it, loss=0.142, loss_mlm=0.981, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 33/1000000 [06:33<3111:03:25, 11.20s/it, loss=0.0408, loss_mlm=0.865, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 34/1000000 [06:33<3112:29:45, 11.21s/it, loss=0.0408, loss_mlm=0.865, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 34/1000000 [06:44<3112:29:45, 11.21s/it, loss=0.0253, loss_mlm=0.926, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 35/1000000 [06:44<3114:46:58, 11.21s/it, loss=0.0253, loss_mlm=0.926, lr=0.002, norm_mask=8.02, norm_target=9.06]Steps:   0%|          | 35/1000000 [06:55<3114:46:58, 11.21s/it, loss=0.0568, loss_mlm=0.923, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 36/1000000 [06:55<3117:17:57, 11.22s/it, loss=0.0568, loss_mlm=0.923, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 36/1000000 [07:06<3117:17:57, 11.22s/it, loss=0.00853, loss_mlm=1.01, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 37/1000000 [07:06<3117:16:15, 11.22s/it, loss=0.00853, loss_mlm=1.01, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 37/1000000 [07:18<3117:16:15, 11.22s/it, loss=0.0297, loss_mlm=0.735, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 38/1000000 [07:18<3116:15:44, 11.22s/it, loss=0.0297, loss_mlm=0.735, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 38/1000000 [07:29<3116:15:44, 11.22s/it, loss=0.0135, loss_mlm=1.21, lr=0.002, norm_mask=8.02, norm_target=9.22] Steps:   0%|          | 39/1000000 [07:29<3114:27:23, 11.21s/it, loss=0.0135, loss_mlm=1.21, lr=0.002, norm_mask=8.02, norm_target=9.22]Steps:   0%|          | 39/1000000 [07:40<3114:27:23, 11.21s/it, loss=0.0235, loss_mlm=0.954, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 40/1000000 [07:40<3139:31:31, 11.30s/it, loss=0.0235, loss_mlm=0.954, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 40/1000000 [07:52<3139:31:31, 11.30s/it, loss=0.00506, loss_mlm=0.93, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 41/1000000 [07:52<3131:19:10, 11.27s/it, loss=0.00506, loss_mlm=0.93, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 41/1000000 [08:03<3131:19:10, 11.27s/it, loss=0.0431, loss_mlm=0.708, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 42/1000000 [08:03<3125:51:26, 11.25s/it, loss=0.0431, loss_mlm=0.708, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 42/1000000 [08:14<3125:51:26, 11.25s/it, loss=0.24, loss_mlm=0.61, lr=0.002, norm_mask=8.02, norm_target=9.38]   Steps:   0%|          | 43/1000000 [08:14<3121:43:32, 11.24s/it, loss=0.24, loss_mlm=0.61, lr=0.002, norm_mask=8.02, norm_target=9.38]Steps:   0%|          | 43/1000000 [08:25<3121:43:32, 11.24s/it, loss=0.00497, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 44/1000000 [08:25<3118:42:09, 11.23s/it, loss=0.00497, loss_mlm=1.19, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 44/1000000 [08:36<3118:42:09, 11.23s/it, loss=0.00973, loss_mlm=0.846, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 45/1000000 [08:36<3117:02:55, 11.22s/it, loss=0.00973, loss_mlm=0.846, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 45/1000000 [08:48<3117:02:55, 11.22s/it, loss=0.00363, loss_mlm=0.614, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 46/1000000 [08:48<3115:32:11, 11.22s/it, loss=0.00363, loss_mlm=0.614, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 46/1000000 [08:59<3115:32:11, 11.22s/it, loss=0.00657, loss_mlm=1.21, lr=0.002, norm_mask=8.02, norm_target=9.55] Steps:   0%|          | 47/1000000 [08:59<3114:16:06, 11.21s/it, loss=0.00657, loss_mlm=1.21, lr=0.002, norm_mask=8.02, norm_target=9.55]Steps:   0%|          | 47/1000000 [09:10<3114:16:06, 11.21s/it, loss=0.259, loss_mlm=0.752, lr=0.002, norm_mask=8.02, norm_target=9.71] Steps:   0%|          | 48/1000000 [09:10<3112:38:39, 11.21s/it, loss=0.259, loss_mlm=0.752, lr=0.002, norm_mask=8.02, norm_target=9.71]Steps:   0%|          | 48/1000000 [09:21<3112:38:39, 11.21s/it, loss=0.00266, loss_mlm=0.829, lr=0.002, norm_mask=8.02, norm_target=9.71]Steps:   0%|          | 49/1000000 [09:21<3112:49:25, 11.21s/it, loss=0.00266, loss_mlm=0.829, lr=0.002, norm_mask=8.02, norm_target=9.71]Steps:   0%|          | 49/1000000 [09:32<3112:49:25, 11.21s/it, loss=0.00349, loss_mlm=1, lr=0.002, norm_mask=8.02, norm_target=9.71]    Steps:   0%|          | 50/1000000 [09:32<3112:08:33, 11.20s/it, loss=0.00349, loss_mlm=1, lr=0.002, norm_mask=8.02, norm_target=9.71]