INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type', 'sample_max_value', 'thresholding', 'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'num_attention_heads', 'upcast_attention', 'conv_out_kernel', 'dual_cross_attention', 'addition_time_embed_dim', 'use_linear_projection', 'timestep_post_act', 'class_embed_type', 'resnet_skip_time_act', 'transformer_layers_per_block', 'num_class_embeds', 'time_cond_proj_dim', 'cross_attention_norm', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'conv_in_kernel', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'mid_block_type', 'encoder_hid_dim_type', 'addition_embed_type', 'class_embeddings_concat', 'time_embedding_dim', 'mid_block_only_cross_attention', 'time_embedding_act_fn', 'only_cross_attention', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
[49409] mask_token_ids
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
position_ids defined_key-clsnet
final.weight defined_key-clsnet
final.bias defined_key-clsnet
position_embedding.weight defined_key-clsnet
multi_head_attention1.in_proj_weight defined_key-clsnet
multi_head_attention1.in_proj_bias defined_key-clsnet
multi_head_attention1.out_proj.weight defined_key-clsnet
multi_head_attention1.out_proj.bias defined_key-clsnet
feed_forward1.W_ff1.weight defined_key-clsnet
feed_forward1.W_ff1.bias defined_key-clsnet
feed_forward1.W_ff2.weight defined_key-clsnet
feed_forward1.W_ff2.bias defined_key-clsnet
layer_norm1.weight defined_key-clsnet
layer_norm1.bias defined_key-clsnet
multi_head_attention2.in_proj_weight defined_key-clsnet
multi_head_attention2.in_proj_bias defined_key-clsnet
multi_head_attention2.out_proj.weight defined_key-clsnet
multi_head_attention2.out_proj.bias defined_key-clsnet
layer_norm2.weight defined_key-clsnet
layer_norm2.bias defined_key-clsnet

module.position_ids saved_key-clsnet
module.final.weight saved_key-clsnet
module.final.bias saved_key-clsnet
module.position_embedding.weight saved_key-clsnet
module.multi_head_attention1.in_proj_weight saved_key-clsnet
module.multi_head_attention1.in_proj_bias saved_key-clsnet
module.multi_head_attention1.out_proj.weight saved_key-clsnet
module.multi_head_attention1.out_proj.bias saved_key-clsnet
module.feed_forward1.W_ff1.weight saved_key-clsnet
module.feed_forward1.W_ff1.bias saved_key-clsnet
module.feed_forward1.W_ff2.weight saved_key-clsnet
module.feed_forward1.W_ff2.bias saved_key-clsnet
module.layer_norm1.weight saved_key-clsnet
module.layer_norm1.bias saved_key-clsnet
module.multi_head_attention2.in_proj_weight saved_key-clsnet
module.multi_head_attention2.in_proj_bias saved_key-clsnet
module.multi_head_attention2.out_proj.weight saved_key-clsnet
module.multi_head_attention2.out_proj.bias saved_key-clsnet
module.layer_norm2.weight saved_key-clsnet
module.layer_norm2.bias saved_key-clsnet
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:15<?, ?it/s, loss=0.163, loss_mlm=0.862, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:15<4188:43:09, 15.08s/it, loss=0.163, loss_mlm=0.862, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:26<4188:43:09, 15.08s/it, loss=0.295, loss_mlm=0.963, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:26<3579:47:30, 12.89s/it, loss=0.295, loss_mlm=0.963, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:37<3579:47:30, 12.89s/it, loss=0.0543, loss_mlm=0.655, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:37<3377:09:09, 12.16s/it, loss=0.0543, loss_mlm=0.655, lr=0.004, norm_mask=8.02, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:49<3377:09:09, 12.16s/it, loss=0.00501, loss_mlm=0.953, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 4/1000000 [00:49<3285:33:14, 11.83s/it, loss=0.00501, loss_mlm=0.953, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 4/1000000 [01:00<3285:33:14, 11.83s/it, loss=0.0123, loss_mlm=0.653, lr=0.004, norm_mask=8.02, norm_target=8.51] Steps:   0%|          | 5/1000000 [01:00<3232:48:45, 11.64s/it, loss=0.0123, loss_mlm=0.653, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 5/1000000 [01:11<3232:48:45, 11.64s/it, loss=0.0586, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=8.51] Steps:   0%|          | 6/1000000 [01:11<3200:20:17, 11.52s/it, loss=0.0586, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 6/1000000 [01:22<3200:20:17, 11.52s/it, loss=0.0755, loss_mlm=0.933, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 7/1000000 [01:22<3178:53:36, 11.44s/it, loss=0.0755, loss_mlm=0.933, lr=0.004, norm_mask=8.02, norm_target=8.51]Steps:   0%|          | 7/1000000 [01:34<3178:53:36, 11.44s/it, loss=0.0636, loss_mlm=0.592, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 8/1000000 [01:34<3165:21:31, 11.40s/it, loss=0.0636, loss_mlm=0.592, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 8/1000000 [01:45<3165:21:31, 11.40s/it, loss=0.148, loss_mlm=0.886, lr=0.004, norm_mask=8.02, norm_target=8.99] Steps:   0%|          | 9/1000000 [01:45<3156:49:57, 11.36s/it, loss=0.148, loss_mlm=0.886, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 9/1000000 [01:56<3156:49:57, 11.36s/it, loss=0.0625, loss_mlm=0.969, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 10/1000000 [01:56<3150:51:52, 11.34s/it, loss=0.0625, loss_mlm=0.969, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 10/1000000 [02:08<3150:51:52, 11.34s/it, loss=0.0196, loss_mlm=0.573, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:08<3145:55:08, 11.33s/it, loss=0.0196, loss_mlm=0.573, lr=0.004, norm_mask=8.02, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:19<3145:55:08, 11.33s/it, loss=0.0806, loss_mlm=1.11, lr=0.004, norm_mask=8.02, norm_target=9.52] Steps:   0%|          | 12/1000000 [02:19<3143:39:49, 11.32s/it, loss=0.0806, loss_mlm=1.11, lr=0.004, norm_mask=8.02, norm_target=9.52]Steps:   0%|          | 12/1000000 [02:30<3143:39:49, 11.32s/it, loss=0.0438, loss_mlm=0.636, lr=0.004, norm_mask=8.02, norm_target=9.52]Steps:   0%|          | 13/1000000 [02:30<3141:28:14, 11.31s/it, loss=0.0438, loss_mlm=0.636, lr=0.004, norm_mask=8.02, norm_target=9.52]Steps:   0%|          | 13/1000000 [02:41<3141:28:14, 11.31s/it, loss=0.0798, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=9.52] Steps:   0%|          | 14/1000000 [02:41<3139:48:26, 11.30s/it, loss=0.0798, loss_mlm=1.15, lr=0.004, norm_mask=8.02, norm_target=9.52]Steps:   0%|          | 14/1000000 [02:53<3139:48:26, 11.30s/it, loss=0.0207, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=9.52]   Steps:   0%|          | 15/1000000 [02:53<3138:07:23, 11.30s/it, loss=0.0207, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=9.52]Steps:   0%|          | 15/1000000 [03:04<3138:07:23, 11.30s/it, loss=0.236, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 16/1000000 [03:04<3137:34:24, 11.30s/it, loss=0.236, loss_mlm=1.16, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 16/1000000 [03:15<3137:34:24, 11.30s/it, loss=0.00838, loss_mlm=0.714, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 17/1000000 [03:15<3137:04:16, 11.29s/it, loss=0.00838, loss_mlm=0.714, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 17/1000000 [03:27<3137:04:16, 11.29s/it, loss=0.196, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=10]   Steps:   0%|          | 18/1000000 [03:27<3136:09:18, 11.29s/it, loss=0.196, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 18/1000000 [03:38<3136:09:18, 11.29s/it, loss=0.00709, loss_mlm=0.765, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 19/1000000 [03:38<3164:58:11, 11.39s/it, loss=0.00709, loss_mlm=0.765, lr=0.004, norm_mask=8.02, norm_target=10]Steps:   0%|          | 19/1000000 [03:50<3164:58:11, 11.39s/it, loss=0.00182, loss_mlm=0.736, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 20/1000000 [03:50<3155:51:54, 11.36s/it, loss=0.00182, loss_mlm=0.736, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 20/1000000 [04:01<3155:51:54, 11.36s/it, loss=0.0438, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=10.6]  Steps:   0%|          | 21/1000000 [04:01<3149:21:30, 11.34s/it, loss=0.0438, loss_mlm=1.14, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 21/1000000 [04:12<3149:21:30, 11.34s/it, loss=0.0943, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:12<3146:41:11, 11.33s/it, loss=0.0943, loss_mlm=1.06, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:23<3146:41:11, 11.33s/it, loss=0.041, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=10.6] Steps:   0%|          | 23/1000000 [04:23<3143:59:43, 11.32s/it, loss=0.041, loss_mlm=1.12, lr=0.004, norm_mask=8.02, norm_target=10.6]Steps:   0%|          | 23/1000000 [04:35<3143:59:43, 11.32s/it, loss=0.0682, loss_mlm=0.832, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 24/1000000 [04:35<3142:34:58, 11.31s/it, loss=0.0682, loss_mlm=0.832, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 24/1000000 [04:46<3142:34:58, 11.31s/it, loss=0.0566, loss_mlm=0.907, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 25/1000000 [04:46<3141:17:44, 11.31s/it, loss=0.0566, loss_mlm=0.907, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 25/1000000 [04:57<3141:17:44, 11.31s/it, loss=0.124, loss_mlm=0.847, lr=0.004, norm_mask=8.02, norm_target=11] Steps:   0%|          | 26/1000000 [04:57<3140:34:43, 11.31s/it, loss=0.124, loss_mlm=0.847, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 26/1000000 [05:09<3140:34:43, 11.31s/it, loss=0.0281, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 27/1000000 [05:09<3139:37:28, 11.30s/it, loss=0.0281, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=11]Steps:   0%|          | 27/1000000 [05:20<3139:37:28, 11.30s/it, loss=0.108, loss_mlm=0.595, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 28/1000000 [05:20<3138:40:41, 11.30s/it, loss=0.108, loss_mlm=0.595, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 28/1000000 [05:31<3138:40:41, 11.30s/it, loss=0.0848, loss_mlm=1.26, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 29/1000000 [05:31<3138:24:14, 11.30s/it, loss=0.0848, loss_mlm=1.26, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 29/1000000 [05:43<3138:24:14, 11.30s/it, loss=0.0849, loss_mlm=0.837, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 30/1000000 [05:43<3138:39:12, 11.30s/it, loss=0.0849, loss_mlm=0.837, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 30/1000000 [05:54<3138:39:12, 11.30s/it, loss=0.113, loss_mlm=1.3, lr=0.004, norm_mask=8.02, norm_target=11.5]   Steps:   0%|          | 31/1000000 [05:54<3138:25:50, 11.30s/it, loss=0.113, loss_mlm=1.3, lr=0.004, norm_mask=8.02, norm_target=11.5]Steps:   0%|          | 31/1000000 [06:05<3138:25:50, 11.30s/it, loss=0.0526, loss_mlm=0.816, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 32/1000000 [06:05<3137:54:12, 11.30s/it, loss=0.0526, loss_mlm=0.816, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 32/1000000 [06:16<3137:54:12, 11.30s/it, loss=0.089, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=11.9]  Steps:   0%|          | 33/1000000 [06:16<3137:36:57, 11.30s/it, loss=0.089, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 33/1000000 [06:28<3137:36:57, 11.30s/it, loss=0.0702, loss_mlm=0.984, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 34/1000000 [06:28<3137:36:32, 11.30s/it, loss=0.0702, loss_mlm=0.984, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 34/1000000 [06:39<3137:36:32, 11.30s/it, loss=0.0143, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=11.9]    Steps:   0%|          | 35/1000000 [06:39<3137:53:36, 11.30s/it, loss=0.0143, loss_mlm=1, lr=0.004, norm_mask=8.02, norm_target=11.9]Steps:   0%|          | 35/1000000 [06:50<3137:53:36, 11.30s/it, loss=0.0626, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 36/1000000 [06:50<3137:45:04, 11.30s/it, loss=0.0626, loss_mlm=1.03, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 36/1000000 [07:02<3137:45:04, 11.30s/it, loss=0.0124, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 37/1000000 [07:02<3139:44:56, 11.30s/it, loss=0.0124, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 37/1000000 [07:13<3139:44:56, 11.30s/it, loss=0.0696, loss_mlm=0.84, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:13<3139:06:20, 11.30s/it, loss=0.0696, loss_mlm=0.84, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:24<3139:06:20, 11.30s/it, loss=0.0104, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:24<3138:41:21, 11.30s/it, loss=0.0104, loss_mlm=1.28, lr=0.004, norm_mask=8.02, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:36<3138:41:21, 11.30s/it, loss=0.0347, loss_mlm=0.994, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 40/1000000 [07:36<3167:12:40, 11.40s/it, loss=0.0347, loss_mlm=0.994, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 40/1000000 [07:47<3167:12:40, 11.40s/it, loss=0.0145, loss_mlm=0.993, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 41/1000000 [07:47<3157:59:37, 11.37s/it, loss=0.0145, loss_mlm=0.993, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 41/1000000 [07:58<3157:59:37, 11.37s/it, loss=0.0277, loss_mlm=0.749, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 42/1000000 [07:58<3151:52:13, 11.35s/it, loss=0.0277, loss_mlm=0.749, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 42/1000000 [08:10<3151:52:13, 11.35s/it, loss=0.151, loss_mlm=0.691, lr=0.004, norm_mask=8.02, norm_target=12.6] Steps:   0%|          | 43/1000000 [08:10<3147:59:21, 11.33s/it, loss=0.151, loss_mlm=0.691, lr=0.004, norm_mask=8.02, norm_target=12.6]Steps:   0%|          | 43/1000000 [08:21<3147:59:21, 11.33s/it, loss=0.203, loss_mlm=1.27, lr=0.004, norm_mask=8.02, norm_target=13]   Steps:   0%|          | 44/1000000 [08:21<3145:40:09, 11.32s/it, loss=0.203, loss_mlm=1.27, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 44/1000000 [08:32<3145:40:09, 11.32s/it, loss=0.045, loss_mlm=0.909, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 45/1000000 [08:32<3144:47:21, 11.32s/it, loss=0.045, loss_mlm=0.909, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 45/1000000 [08:44<3144:47:21, 11.32s/it, loss=0.017, loss_mlm=0.659, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 46/1000000 [08:44<3142:21:29, 11.31s/it, loss=0.017, loss_mlm=0.659, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 46/1000000 [08:55<3142:21:29, 11.31s/it, loss=0.0961, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 47/1000000 [08:55<3141:09:04, 11.31s/it, loss=0.0961, loss_mlm=1.23, lr=0.004, norm_mask=8.02, norm_target=13]Steps:   0%|          | 47/1000000 [09:06<3141:09:04, 11.31s/it, loss=0.136, loss_mlm=0.879, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 48/1000000 [09:06<3141:03:49, 11.31s/it, loss=0.136, loss_mlm=0.879, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 48/1000000 [09:18<3141:03:49, 11.31s/it, loss=0.00469, loss_mlm=0.906, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 49/1000000 [09:18<3139:26:01, 11.30s/it, loss=0.00469, loss_mlm=0.906, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 49/1000000 [09:29<3139:26:01, 11.30s/it, loss=0.00693, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=13.3] Steps:   0%|          | 50/1000000 [09:29<3138:29:53, 11.30s/it, loss=0.00693, loss_mlm=1.07, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 50/1000000 [09:40<3138:29:53, 11.30s/it, loss=0.0129, loss_mlm=0.856, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 51/1000000 [09:40<3137:57:30, 11.30s/it, loss=0.0129, loss_mlm=0.856, lr=0.004, norm_mask=8.02, norm_target=13.3]Steps:   0%|          | 51/1000000 [09:51<3137:57:30, 11.30s/it, loss=0.221, loss_mlm=0.807, lr=0.004, norm_mask=8.02, norm_target=13.7] Steps:   0%|          | 52/1000000 [09:51<3137:50:03, 11.30s/it, loss=0.221, loss_mlm=0.807, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 52/1000000 [10:03<3137:50:03, 11.30s/it, loss=0.0551, loss_mlm=0.846, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 53/1000000 [10:03<3137:58:11, 11.30s/it, loss=0.0551, loss_mlm=0.846, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 53/1000000 [10:14<3137:58:11, 11.30s/it, loss=0.0607, loss_mlm=0.886, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:14<3137:17:25, 11.29s/it, loss=0.0607, loss_mlm=0.886, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:25<3137:17:25, 11.29s/it, loss=0.132, loss_mlm=0.974, lr=0.004, norm_mask=8.02, norm_target=13.7] Steps:   0%|          | 55/1000000 [10:25<3137:02:04, 11.29s/it, loss=0.132, loss_mlm=0.974, lr=0.004, norm_mask=8.02, norm_target=13.7]Steps:   0%|          | 55/1000000 [10:37<3137:02:04, 11.29s/it, loss=0.157, loss_mlm=0.838, lr=0.004, norm_mask=8.02, norm_target=14]  Steps:   0%|          | 56/1000000 [10:37<3136:50:32, 11.29s/it, loss=0.157, loss_mlm=0.838, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 56/1000000 [10:48<3136:50:32, 11.29s/it, loss=0.153, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=14] Steps:   0%|          | 57/1000000 [10:48<3136:47:52, 11.29s/it, loss=0.153, loss_mlm=1.29, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 57/1000000 [10:59<3136:47:52, 11.29s/it, loss=0.0938, loss_mlm=0.919, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 58/1000000 [10:59<3136:33:18, 11.29s/it, loss=0.0938, loss_mlm=0.919, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 58/1000000 [11:10<3136:33:18, 11.29s/it, loss=0.0447, loss_mlm=1.13, lr=0.004, norm_mask=8.02, norm_target=14] Steps:   0%|          | 59/1000000 [11:10<3136:23:11, 11.29s/it, loss=0.0447, loss_mlm=1.13, lr=0.004, norm_mask=8.02, norm_target=14]Steps:   0%|          | 59/1000000 [11:22<3136:23:11, 11.29s/it, loss=0.0553, loss_mlm=0.811, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 60/1000000 [11:22<3137:08:02, 11.29s/it, loss=0.0553, loss_mlm=0.811, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 60/1000000 [11:33<3137:08:02, 11.29s/it, loss=0.0254, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.3] Steps:   0%|          | 61/1000000 [11:33<3163:24:37, 11.39s/it, loss=0.0254, loss_mlm=1.08, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 61/1000000 [11:45<3163:24:37, 11.39s/it, loss=0.123, loss_mlm=0.786, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 62/1000000 [11:45<3155:02:44, 11.36s/it, loss=0.123, loss_mlm=0.786, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 62/1000000 [11:56<3155:02:44, 11.36s/it, loss=0.0663, loss_mlm=0.948, lr=0.004, norm_mask=8.02, norm_target=14.3]Steps:   0%|          | 63/1000000 [11:56<3150:34:14, 11.34s/it, loss=0.0663, loss_mlm=0.948, lr=0.004, norm_mask=8.02, norm_target=14.3]