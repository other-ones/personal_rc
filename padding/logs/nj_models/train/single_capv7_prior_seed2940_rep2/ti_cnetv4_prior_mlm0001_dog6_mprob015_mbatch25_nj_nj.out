INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'sample_max_value', 'clip_sample_range', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio', 'prediction_type', 'thresholding'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'addition_time_embed_dim', 'time_embedding_act_fn', 'transformer_layers_per_block', 'conv_in_kernel', 'addition_embed_type', 'num_attention_heads', 'addition_embed_type_num_heads', 'upcast_attention', 'time_cond_proj_dim', 'mid_block_only_cross_attention', 'class_embed_type', 'time_embedding_type', 'encoder_hid_dim', 'class_embeddings_concat', 'cross_attention_norm', 'resnet_out_scale_factor', 'num_class_embeds', 'resnet_skip_time_act', 'only_cross_attention', 'conv_out_kernel', 'encoder_hid_dim_type', 'dual_cross_attention', 'use_linear_projection', 'resnet_time_scale_shift', 'projection_class_embeddings_input_dim', 'timestep_post_act', 'mid_block_type', 'time_embedding_dim'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
None mask_token_ids
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:21<?, ?it/s, loss=0.163, lr=0.004, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:21<5992:31:02, 21.57s/it, loss=0.163, lr=0.004, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:38<5992:31:02, 21.57s/it, loss=0.295, lr=0.004, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:38<5183:53:19, 18.66s/it, loss=0.295, lr=0.004, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:54<5183:53:19, 18.66s/it, loss=0.0542, lr=0.004, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:54<4914:29:57, 17.69s/it, loss=0.0542, lr=0.004, norm_target=8.12]Steps:   0%|          | 3/1000000 [01:11<4914:29:57, 17.69s/it, loss=0.00491, lr=0.004, norm_target=8.51]Steps:   0%|          | 4/1000000 [01:11<4791:31:45, 17.25s/it, loss=0.00491, lr=0.004, norm_target=8.51]Steps:   0%|          | 4/1000000 [01:27<4791:31:45, 17.25s/it, loss=0.0123, lr=0.004, norm_target=8.51] Steps:   0%|          | 5/1000000 [01:27<4720:37:55, 16.99s/it, loss=0.0123, lr=0.004, norm_target=8.51]Steps:   0%|          | 5/1000000 [01:38<4720:37:55, 16.99s/it, loss=0.0585, lr=0.004, norm_target=8.51]Steps:   0%|          | 6/1000000 [01:38<4163:59:57, 14.99s/it, loss=0.0585, lr=0.004, norm_target=8.51]Steps:   0%|          | 6/1000000 [01:50<4163:59:57, 14.99s/it, loss=0.0754, lr=0.004, norm_target=8.51]Steps:   0%|          | 7/1000000 [01:50<3811:34:51, 13.72s/it, loss=0.0754, lr=0.004, norm_target=8.51]Steps:   0%|          | 7/1000000 [02:01<3811:34:51, 13.72s/it, loss=0.0635, lr=0.004, norm_target=8.99]Steps:   0%|          | 8/1000000 [02:01<3579:26:59, 12.89s/it, loss=0.0635, lr=0.004, norm_target=8.99]Steps:   0%|          | 8/1000000 [02:12<3579:26:59, 12.89s/it, loss=0.148, lr=0.004, norm_target=8.99] Steps:   0%|          | 9/1000000 [02:12<3425:10:55, 12.33s/it, loss=0.148, lr=0.004, norm_target=8.99]Steps:   0%|          | 9/1000000 [02:23<3425:10:55, 12.33s/it, loss=0.0624, lr=0.004, norm_target=8.99]Steps:   0%|          | 10/1000000 [02:23<3319:15:06, 11.95s/it, loss=0.0624, lr=0.004, norm_target=8.99]Steps:   0%|          | 10/1000000 [02:34<3319:15:06, 11.95s/it, loss=0.0195, lr=0.004, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:34<3247:01:14, 11.69s/it, loss=0.0195, lr=0.004, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:45<3247:01:14, 11.69s/it, loss=0.0804, lr=0.004, norm_target=9.51]Steps:   0%|          | 12/1000000 [02:45<3196:57:51, 11.51s/it, loss=0.0804, lr=0.004, norm_target=9.51]Steps:   0%|          | 12/1000000 [02:56<3196:57:51, 11.51s/it, loss=0.0437, lr=0.004, norm_target=9.51]Steps:   0%|          | 13/1000000 [02:56<3162:52:49, 11.39s/it, loss=0.0437, lr=0.004, norm_target=9.51]Steps:   0%|          | 13/1000000 [03:07<3162:52:49, 11.39s/it, loss=0.0797, lr=0.004, norm_target=9.51]Steps:   0%|          | 14/1000000 [03:07<3138:05:15, 11.30s/it, loss=0.0797, lr=0.004, norm_target=9.51]Steps:   0%|          | 14/1000000 [03:18<3138:05:15, 11.30s/it, loss=0.0206, lr=0.004, norm_target=9.51]Steps:   0%|          | 15/1000000 [03:18<3121:09:34, 11.24s/it, loss=0.0206, lr=0.004, norm_target=9.51]Steps:   0%|          | 15/1000000 [03:29<3121:09:34, 11.24s/it, loss=0.236, lr=0.004, norm_target=10]   Steps:   0%|          | 16/1000000 [03:29<3108:54:28, 11.19s/it, loss=0.236, lr=0.004, norm_target=10]Steps:   0%|          | 16/1000000 [03:41<3108:54:28, 11.19s/it, loss=0.00831, lr=0.004, norm_target=10]Steps:   0%|          | 17/1000000 [03:41<3099:42:48, 11.16s/it, loss=0.00831, lr=0.004, norm_target=10]Steps:   0%|          | 17/1000000 [03:52<3099:42:48, 11.16s/it, loss=0.196, lr=0.004, norm_target=10]  Steps:   0%|          | 18/1000000 [03:52<3094:23:06, 11.14s/it, loss=0.196, lr=0.004, norm_target=10]Steps:   0%|          | 18/1000000 [04:03<3094:23:06, 11.14s/it, loss=0.00701, lr=0.004, norm_target=10]Steps:   0%|          | 19/1000000 [04:03<3090:12:45, 11.12s/it, loss=0.00701, lr=0.004, norm_target=10]Steps:   0%|          | 19/1000000 [04:14<3090:12:45, 11.12s/it, loss=0.00175, lr=0.004, norm_target=10.6]Steps:   0%|          | 20/1000000 [04:14<3087:27:07, 11.12s/it, loss=0.00175, lr=0.004, norm_target=10.6]Steps:   0%|          | 20/1000000 [04:25<3087:27:07, 11.12s/it, loss=0.0437, lr=0.004, norm_target=10.6] Steps:   0%|          | 21/1000000 [04:25<3085:33:19, 11.11s/it, loss=0.0437, lr=0.004, norm_target=10.6]Steps:   0%|          | 21/1000000 [04:36<3085:33:19, 11.11s/it, loss=0.0942, lr=0.004, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:36<3084:12:19, 11.10s/it, loss=0.0942, lr=0.004, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:47<3084:12:19, 11.10s/it, loss=0.0409, lr=0.004, norm_target=10.6]Steps:   0%|          | 23/1000000 [04:47<3083:14:18, 11.10s/it, loss=0.0409, lr=0.004, norm_target=10.6]Steps:   0%|          | 23/1000000 [04:58<3083:14:18, 11.10s/it, loss=0.0681, lr=0.004, norm_target=11]  Steps:   0%|          | 24/1000000 [04:58<3082:15:53, 11.10s/it, loss=0.0681, lr=0.004, norm_target=11]Steps:   0%|          | 24/1000000 [05:10<3082:15:53, 11.10s/it, loss=0.0565, lr=0.004, norm_target=11]Steps:   0%|          | 25/1000000 [05:10<3106:22:26, 11.18s/it, loss=0.0565, lr=0.004, norm_target=11]Steps:   0%|          | 25/1000000 [05:21<3106:22:26, 11.18s/it, loss=0.123, lr=0.004, norm_target=11] Steps:   0%|          | 26/1000000 [05:21<3098:31:49, 11.15s/it, loss=0.123, lr=0.004, norm_target=11]Steps:   0%|          | 26/1000000 [05:32<3098:31:49, 11.15s/it, loss=0.028, lr=0.004, norm_target=11]Steps:   0%|          | 27/1000000 [05:32<3092:58:59, 11.14s/it, loss=0.028, lr=0.004, norm_target=11]Steps:   0%|          | 27/1000000 [05:43<3092:58:59, 11.14s/it, loss=0.108, lr=0.004, norm_target=11.4]Steps:   0%|          | 28/1000000 [05:43<3089:07:36, 11.12s/it, loss=0.108, lr=0.004, norm_target=11.4]Steps:   0%|          | 28/1000000 [05:54<3089:07:36, 11.12s/it, loss=0.0847, lr=0.004, norm_target=11.4]Steps:   0%|          | 29/1000000 [05:54<3086:20:36, 11.11s/it, loss=0.0847, lr=0.004, norm_target=11.4]Steps:   0%|          | 29/1000000 [06:05<3086:20:36, 11.11s/it, loss=0.0848, lr=0.004, norm_target=11.4]Steps:   0%|          | 30/1000000 [06:05<3084:37:41, 11.10s/it, loss=0.0848, lr=0.004, norm_target=11.4]Steps:   0%|          | 30/1000000 [06:16<3084:37:41, 11.10s/it, loss=0.113, lr=0.004, norm_target=11.4] Steps:   0%|          | 31/1000000 [06:16<3083:20:36, 11.10s/it, loss=0.113, lr=0.004, norm_target=11.4]Steps:   0%|          | 31/1000000 [06:27<3083:20:36, 11.10s/it, loss=0.0525, lr=0.004, norm_target=11.8]Steps:   0%|          | 32/1000000 [06:27<3082:24:22, 11.10s/it, loss=0.0525, lr=0.004, norm_target=11.8]Steps:   0%|          | 32/1000000 [06:38<3082:24:22, 11.10s/it, loss=0.0889, lr=0.004, norm_target=11.8]Steps:   0%|          | 33/1000000 [06:38<3081:49:13, 11.09s/it, loss=0.0889, lr=0.004, norm_target=11.8]Steps:   0%|          | 33/1000000 [06:49<3081:49:13, 11.09s/it, loss=0.0701, lr=0.004, norm_target=11.8]Steps:   0%|          | 34/1000000 [06:49<3081:31:47, 11.09s/it, loss=0.0701, lr=0.004, norm_target=11.8]Steps:   0%|          | 34/1000000 [07:00<3081:31:47, 11.09s/it, loss=0.0142, lr=0.004, norm_target=11.8]Steps:   0%|          | 35/1000000 [07:00<3081:08:26, 11.09s/it, loss=0.0142, lr=0.004, norm_target=11.8]Steps:   0%|          | 35/1000000 [07:12<3081:08:26, 11.09s/it, loss=0.0626, lr=0.004, norm_target=12.2]Steps:   0%|          | 36/1000000 [07:12<3080:52:59, 11.09s/it, loss=0.0626, lr=0.004, norm_target=12.2]Steps:   0%|          | 36/1000000 [07:23<3080:52:59, 11.09s/it, loss=0.0122, lr=0.004, norm_target=12.2]Steps:   0%|          | 37/1000000 [07:23<3080:46:50, 11.09s/it, loss=0.0122, lr=0.004, norm_target=12.2]Steps:   0%|          | 37/1000000 [07:34<3080:46:50, 11.09s/it, loss=0.0695, lr=0.004, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:34<3080:32:52, 11.09s/it, loss=0.0695, lr=0.004, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:45<3080:32:52, 11.09s/it, loss=0.0103, lr=0.004, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:45<3080:58:44, 11.09s/it, loss=0.0103, lr=0.004, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:56<3080:58:44, 11.09s/it, loss=0.0346, lr=0.004, norm_target=12.6]Steps:   0%|          | 40/1000000 [07:56<3080:54:47, 11.09s/it, loss=0.0346, lr=0.004, norm_target=12.6]Steps:   0%|          | 40/1000000 [08:07<3080:54:47, 11.09s/it, loss=0.0144, lr=0.004, norm_target=12.6]Steps:   0%|          | 41/1000000 [08:07<3080:48:24, 11.09s/it, loss=0.0144, lr=0.004, norm_target=12.6]Steps:   0%|          | 41/1000000 [08:18<3080:48:24, 11.09s/it, loss=0.0276, lr=0.004, norm_target=12.6]Steps:   0%|          | 42/1000000 [08:18<3081:04:01, 11.09s/it, loss=0.0276, lr=0.004, norm_target=12.6]Steps:   0%|          | 42/1000000 [08:29<3081:04:01, 11.09s/it, loss=0.151, lr=0.004, norm_target=12.6] Steps:   0%|          | 43/1000000 [08:29<3080:58:36, 11.09s/it, loss=0.151, lr=0.004, norm_target=12.6]Steps:   0%|          | 43/1000000 [08:40<3080:58:36, 11.09s/it, loss=0.203, lr=0.004, norm_target=13]  Steps:   0%|          | 44/1000000 [08:40<3081:35:12, 11.09s/it, loss=0.203, lr=0.004, norm_target=13]Steps:   0%|          | 44/1000000 [08:51<3081:35:12, 11.09s/it, loss=0.045, lr=0.004, norm_target=13]Steps:   0%|          | 45/1000000 [08:51<3081:33:51, 11.09s/it, loss=0.045, lr=0.004, norm_target=13]Steps:   0%|          | 45/1000000 [09:02<3081:33:51, 11.09s/it, loss=0.0169, lr=0.004, norm_target=13]Steps:   0%|          | 46/1000000 [09:02<3081:12:55, 11.09s/it, loss=0.0169, lr=0.004, norm_target=13]Steps:   0%|          | 46/1000000 [09:14<3081:12:55, 11.09s/it, loss=0.096, lr=0.004, norm_target=13] Steps:   0%|          | 47/1000000 [09:14<3081:11:02, 11.09s/it, loss=0.096, lr=0.004, norm_target=13]Steps:   0%|          | 47/1000000 [09:25<3081:11:02, 11.09s/it, loss=0.135, lr=0.004, norm_target=13.4]Steps:   0%|          | 48/1000000 [09:25<3080:47:01, 11.09s/it, loss=0.135, lr=0.004, norm_target=13.4]Steps:   0%|          | 48/1000000 [09:36<3080:47:01, 11.09s/it, loss=0.00461, lr=0.004, norm_target=13.4]Steps:   0%|          | 49/1000000 [09:36<3080:30:26, 11.09s/it, loss=0.00461, lr=0.004, norm_target=13.4]Steps:   0%|          | 49/1000000 [09:47<3080:30:26, 11.09s/it, loss=0.00682, lr=0.004, norm_target=13.4]Steps:   0%|          | 50/1000000 [09:47<3080:06:17, 11.09s/it, loss=0.00682, lr=0.004, norm_target=13.4]Steps:   0%|          | 50/1000000 [09:58<3080:06:17, 11.09s/it, loss=0.0128, lr=0.004, norm_target=13.4] Steps:   0%|          | 51/1000000 [09:58<3080:17:19, 11.09s/it, loss=0.0128, lr=0.004, norm_target=13.4]Steps:   0%|          | 51/1000000 [10:09<3080:17:19, 11.09s/it, loss=0.221, lr=0.004, norm_target=13.7] Steps:   0%|          | 52/1000000 [10:09<3102:43:49, 11.17s/it, loss=0.221, lr=0.004, norm_target=13.7]Steps:   0%|          | 52/1000000 [10:20<3102:43:49, 11.17s/it, loss=0.055, lr=0.004, norm_target=13.7]Steps:   0%|          | 53/1000000 [10:20<3096:30:27, 11.15s/it, loss=0.055, lr=0.004, norm_target=13.7]Steps:   0%|          | 53/1000000 [10:31<3096:30:27, 11.15s/it, loss=0.0606, lr=0.004, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:31<3092:38:26, 11.13s/it, loss=0.0606, lr=0.004, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:43<3092:38:26, 11.13s/it, loss=0.132, lr=0.004, norm_target=13.7] Steps:   0%|          | 55/1000000 [10:43<3089:02:44, 11.12s/it, loss=0.132, lr=0.004, norm_target=13.7]Steps:   0%|          | 55/1000000 [10:54<3089:02:44, 11.12s/it, loss=0.157, lr=0.004, norm_target=14.1]Steps:   0%|          | 56/1000000 [10:54<3086:37:27, 11.11s/it, loss=0.157, lr=0.004, norm_target=14.1]Steps:   0%|          | 56/1000000 [11:05<3086:37:27, 11.11s/it, loss=0.152, lr=0.004, norm_target=14.1]Steps:   0%|          | 57/1000000 [11:05<3084:35:48, 11.11s/it, loss=0.152, lr=0.004, norm_target=14.1]Steps:   0%|          | 57/1000000 [11:16<3084:35:48, 11.11s/it, loss=0.0937, lr=0.004, norm_target=14.1]Steps:   0%|          | 58/1000000 [11:16<3083:24:15, 11.10s/it, loss=0.0937, lr=0.004, norm_target=14.1]Steps:   0%|          | 58/1000000 [11:27<3083:24:15, 11.10s/it, loss=0.0447, lr=0.004, norm_target=14.1]Steps:   0%|          | 59/1000000 [11:27<3083:02:21, 11.10s/it, loss=0.0447, lr=0.004, norm_target=14.1]Steps:   0%|          | 59/1000000 [11:38<3083:02:21, 11.10s/it, loss=0.0552, lr=0.004, norm_target=14.4]Steps:   0%|          | 60/1000000 [11:38<3082:43:11, 11.10s/it, loss=0.0552, lr=0.004, norm_target=14.4]Steps:   0%|          | 60/1000000 [11:49<3082:43:11, 11.10s/it, loss=0.0253, lr=0.004, norm_target=14.4]Steps:   0%|          | 61/1000000 [11:49<3082:34:17, 11.10s/it, loss=0.0253, lr=0.004, norm_target=14.4]