INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'timestep_spacing', 'dynamic_thresholding_ratio', 'sample_max_value', 'clip_sample_range', 'thresholding', 'prediction_type', 'variance_type'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'mid_block_type', 'timestep_post_act', 'encoder_hid_dim_type', 'conv_in_kernel', 'transformer_layers_per_block', 'upcast_attention', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'addition_embed_type_num_heads', 'time_embedding_dim', 'class_embeddings_concat', 'dual_cross_attention', 'cross_attention_norm', 'conv_out_kernel', 'class_embed_type', 'num_attention_heads', 'mid_block_only_cross_attention', 'time_embedding_act_fn', 'only_cross_attention', 'resnet_out_scale_factor', 'addition_time_embed_dim', 'resnet_skip_time_act', 'time_cond_proj_dim', 'use_linear_projection', 'addition_embed_type', 'resnet_time_scale_shift', 'encoder_hid_dim', 'num_class_embeds'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 2
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 8
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
None mask_token_ids
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
Steps:   0%|          | 0/1000000 [00:13<?, ?it/s, loss=0.163, lr=0.004, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:13<3796:21:55, 13.67s/it, loss=0.163, lr=0.004, norm_target=8.12]Steps:   0%|          | 1/1000000 [00:24<3796:21:55, 13.67s/it, loss=0.295, lr=0.004, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:24<3375:33:34, 12.15s/it, loss=0.295, lr=0.004, norm_target=8.12]Steps:   0%|          | 2/1000000 [00:35<3375:33:34, 12.15s/it, loss=0.0542, lr=0.004, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:35<3241:10:38, 11.67s/it, loss=0.0542, lr=0.004, norm_target=8.12]Steps:   0%|          | 3/1000000 [00:46<3241:10:38, 11.67s/it, loss=0.00491, lr=0.004, norm_target=8.51]Steps:   0%|          | 4/1000000 [00:46<3181:42:43, 11.45s/it, loss=0.00491, lr=0.004, norm_target=8.51]Steps:   0%|          | 4/1000000 [00:58<3181:42:43, 11.45s/it, loss=0.0123, lr=0.004, norm_target=8.51] Steps:   0%|          | 5/1000000 [00:58<3145:51:43, 11.33s/it, loss=0.0123, lr=0.004, norm_target=8.51]Steps:   0%|          | 5/1000000 [01:09<3145:51:43, 11.33s/it, loss=0.0585, lr=0.004, norm_target=8.51]Steps:   0%|          | 6/1000000 [01:09<3124:29:37, 11.25s/it, loss=0.0585, lr=0.004, norm_target=8.51]Steps:   0%|          | 6/1000000 [01:20<3124:29:37, 11.25s/it, loss=0.0754, lr=0.004, norm_target=8.51]Steps:   0%|          | 7/1000000 [01:20<3109:56:45, 11.20s/it, loss=0.0754, lr=0.004, norm_target=8.51]Steps:   0%|          | 7/1000000 [01:31<3109:56:45, 11.20s/it, loss=0.0635, lr=0.004, norm_target=8.99]Steps:   0%|          | 8/1000000 [01:31<3100:55:49, 11.16s/it, loss=0.0635, lr=0.004, norm_target=8.99]Steps:   0%|          | 8/1000000 [01:42<3100:55:49, 11.16s/it, loss=0.148, lr=0.004, norm_target=8.99] Steps:   0%|          | 9/1000000 [01:42<3095:11:45, 11.14s/it, loss=0.148, lr=0.004, norm_target=8.99]Steps:   0%|          | 9/1000000 [01:53<3095:11:45, 11.14s/it, loss=0.0624, lr=0.004, norm_target=8.99]Steps:   0%|          | 10/1000000 [01:53<3091:13:29, 11.13s/it, loss=0.0624, lr=0.004, norm_target=8.99]Steps:   0%|          | 10/1000000 [02:04<3091:13:29, 11.13s/it, loss=0.0195, lr=0.004, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:04<3088:52:24, 11.12s/it, loss=0.0195, lr=0.004, norm_target=8.99]Steps:   0%|          | 11/1000000 [02:15<3088:52:24, 11.12s/it, loss=0.0804, lr=0.004, norm_target=9.51]Steps:   0%|          | 12/1000000 [02:15<3086:52:43, 11.11s/it, loss=0.0804, lr=0.004, norm_target=9.51]Steps:   0%|          | 12/1000000 [02:26<3086:52:43, 11.11s/it, loss=0.0437, lr=0.004, norm_target=9.51]Steps:   0%|          | 13/1000000 [02:26<3087:14:08, 11.11s/it, loss=0.0437, lr=0.004, norm_target=9.51]Steps:   0%|          | 13/1000000 [02:37<3087:14:08, 11.11s/it, loss=0.0797, lr=0.004, norm_target=9.51]Steps:   0%|          | 14/1000000 [02:37<3085:42:14, 11.11s/it, loss=0.0797, lr=0.004, norm_target=9.51]Steps:   0%|          | 14/1000000 [02:49<3085:42:14, 11.11s/it, loss=0.0206, lr=0.004, norm_target=9.51]Steps:   0%|          | 15/1000000 [02:49<3084:15:25, 11.10s/it, loss=0.0206, lr=0.004, norm_target=9.51]Steps:   0%|          | 15/1000000 [03:00<3084:15:25, 11.10s/it, loss=0.236, lr=0.004, norm_target=10]   Steps:   0%|          | 16/1000000 [03:00<3083:29:40, 11.10s/it, loss=0.236, lr=0.004, norm_target=10]Steps:   0%|          | 16/1000000 [03:11<3083:29:40, 11.10s/it, loss=0.00831, lr=0.004, norm_target=10]Steps:   0%|          | 17/1000000 [03:11<3083:02:37, 11.10s/it, loss=0.00831, lr=0.004, norm_target=10]Steps:   0%|          | 17/1000000 [03:22<3083:02:37, 11.10s/it, loss=0.196, lr=0.004, norm_target=10]  Steps:   0%|          | 18/1000000 [03:22<3082:24:25, 11.10s/it, loss=0.196, lr=0.004, norm_target=10]Steps:   0%|          | 18/1000000 [03:33<3082:24:25, 11.10s/it, loss=0.00701, lr=0.004, norm_target=10]Steps:   0%|          | 19/1000000 [03:33<3081:59:05, 11.10s/it, loss=0.00701, lr=0.004, norm_target=10]Steps:   0%|          | 19/1000000 [03:44<3081:59:05, 11.10s/it, loss=0.00175, lr=0.004, norm_target=10.6]Steps:   0%|          | 20/1000000 [03:44<3081:34:53, 11.09s/it, loss=0.00175, lr=0.004, norm_target=10.6]Steps:   0%|          | 20/1000000 [03:55<3081:34:53, 11.09s/it, loss=0.0437, lr=0.004, norm_target=10.6] Steps:   0%|          | 21/1000000 [03:55<3081:29:01, 11.09s/it, loss=0.0437, lr=0.004, norm_target=10.6]Steps:   0%|          | 21/1000000 [04:06<3081:29:01, 11.09s/it, loss=0.0942, lr=0.004, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:06<3082:02:22, 11.10s/it, loss=0.0942, lr=0.004, norm_target=10.6]Steps:   0%|          | 22/1000000 [04:18<3082:02:22, 11.10s/it, loss=0.0409, lr=0.004, norm_target=10.6]Steps:   0%|          | 23/1000000 [04:18<3104:16:57, 11.18s/it, loss=0.0409, lr=0.004, norm_target=10.6]Steps:   0%|          | 23/1000000 [04:29<3104:16:57, 11.18s/it, loss=0.0681, lr=0.004, norm_target=11]  Steps:   0%|          | 24/1000000 [04:29<3097:31:37, 11.15s/it, loss=0.0681, lr=0.004, norm_target=11]Steps:   0%|          | 24/1000000 [04:40<3097:31:37, 11.15s/it, loss=0.0565, lr=0.004, norm_target=11]Steps:   0%|          | 25/1000000 [04:40<3092:49:07, 11.13s/it, loss=0.0565, lr=0.004, norm_target=11]Steps:   0%|          | 25/1000000 [04:51<3092:49:07, 11.13s/it, loss=0.123, lr=0.004, norm_target=11] Steps:   0%|          | 26/1000000 [04:51<3089:13:33, 11.12s/it, loss=0.123, lr=0.004, norm_target=11]Steps:   0%|          | 26/1000000 [05:02<3089:13:33, 11.12s/it, loss=0.028, lr=0.004, norm_target=11]Steps:   0%|          | 27/1000000 [05:02<3088:21:40, 11.12s/it, loss=0.028, lr=0.004, norm_target=11]Steps:   0%|          | 27/1000000 [05:13<3088:21:40, 11.12s/it, loss=0.108, lr=0.004, norm_target=11.4]Steps:   0%|          | 28/1000000 [05:13<3086:37:07, 11.11s/it, loss=0.108, lr=0.004, norm_target=11.4]Steps:   0%|          | 28/1000000 [05:24<3086:37:07, 11.11s/it, loss=0.0847, lr=0.004, norm_target=11.4]Steps:   0%|          | 29/1000000 [05:24<3084:37:08, 11.10s/it, loss=0.0847, lr=0.004, norm_target=11.4]Steps:   0%|          | 29/1000000 [05:35<3084:37:08, 11.10s/it, loss=0.0848, lr=0.004, norm_target=11.4]Steps:   0%|          | 30/1000000 [05:35<3085:01:57, 11.11s/it, loss=0.0848, lr=0.004, norm_target=11.4]Steps:   0%|          | 30/1000000 [05:46<3085:01:57, 11.11s/it, loss=0.113, lr=0.004, norm_target=11.4] Steps:   0%|          | 31/1000000 [05:46<3083:56:28, 11.10s/it, loss=0.113, lr=0.004, norm_target=11.4]Steps:   0%|          | 31/1000000 [05:57<3083:56:28, 11.10s/it, loss=0.0525, lr=0.004, norm_target=11.8]Steps:   0%|          | 32/1000000 [05:57<3083:30:07, 11.10s/it, loss=0.0525, lr=0.004, norm_target=11.8]Steps:   0%|          | 32/1000000 [06:09<3083:30:07, 11.10s/it, loss=0.0889, lr=0.004, norm_target=11.8]Steps:   0%|          | 33/1000000 [06:09<3083:07:00, 11.10s/it, loss=0.0889, lr=0.004, norm_target=11.8]Steps:   0%|          | 33/1000000 [06:20<3083:07:00, 11.10s/it, loss=0.0701, lr=0.004, norm_target=11.8]Steps:   0%|          | 34/1000000 [06:20<3084:00:20, 11.10s/it, loss=0.0701, lr=0.004, norm_target=11.8]Steps:   0%|          | 34/1000000 [06:31<3084:00:20, 11.10s/it, loss=0.0142, lr=0.004, norm_target=11.8]Steps:   0%|          | 35/1000000 [06:31<3083:25:57, 11.10s/it, loss=0.0142, lr=0.004, norm_target=11.8]Steps:   0%|          | 35/1000000 [06:42<3083:25:57, 11.10s/it, loss=0.0626, lr=0.004, norm_target=12.2]Steps:   0%|          | 36/1000000 [06:42<3083:43:10, 11.10s/it, loss=0.0626, lr=0.004, norm_target=12.2]Steps:   0%|          | 36/1000000 [06:53<3083:43:10, 11.10s/it, loss=0.0122, lr=0.004, norm_target=12.2]Steps:   0%|          | 37/1000000 [06:53<3085:18:26, 11.11s/it, loss=0.0122, lr=0.004, norm_target=12.2]Steps:   0%|          | 37/1000000 [07:04<3085:18:26, 11.11s/it, loss=0.0695, lr=0.004, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:04<3084:35:57, 11.10s/it, loss=0.0695, lr=0.004, norm_target=12.2]Steps:   0%|          | 38/1000000 [07:15<3084:35:57, 11.10s/it, loss=0.0103, lr=0.004, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:15<3083:47:08, 11.10s/it, loss=0.0103, lr=0.004, norm_target=12.2]Steps:   0%|          | 39/1000000 [07:26<3083:47:08, 11.10s/it, loss=0.0346, lr=0.004, norm_target=12.6]Steps:   0%|          | 40/1000000 [07:26<3082:45:19, 11.10s/it, loss=0.0346, lr=0.004, norm_target=12.6]Steps:   0%|          | 40/1000000 [07:37<3082:45:19, 11.10s/it, loss=0.0144, lr=0.004, norm_target=12.6]Steps:   0%|          | 41/1000000 [07:37<3082:52:41, 11.10s/it, loss=0.0144, lr=0.004, norm_target=12.6]Steps:   0%|          | 41/1000000 [07:48<3082:52:41, 11.10s/it, loss=0.0276, lr=0.004, norm_target=12.6]Steps:   0%|          | 42/1000000 [07:48<3082:22:21, 11.10s/it, loss=0.0276, lr=0.004, norm_target=12.6]Steps:   0%|          | 42/1000000 [08:00<3082:22:21, 11.10s/it, loss=0.151, lr=0.004, norm_target=12.6] Steps:   0%|          | 43/1000000 [08:00<3081:52:31, 11.10s/it, loss=0.151, lr=0.004, norm_target=12.6]Steps:   0%|          | 43/1000000 [08:11<3081:52:31, 11.10s/it, loss=0.203, lr=0.004, norm_target=13]  Steps:   0%|          | 44/1000000 [08:11<3081:37:37, 11.09s/it, loss=0.203, lr=0.004, norm_target=13]Steps:   0%|          | 44/1000000 [08:22<3081:37:37, 11.09s/it, loss=0.045, lr=0.004, norm_target=13]Steps:   0%|          | 45/1000000 [08:22<3081:45:27, 11.09s/it, loss=0.045, lr=0.004, norm_target=13]Steps:   0%|          | 45/1000000 [08:33<3081:45:27, 11.09s/it, loss=0.0169, lr=0.004, norm_target=13]Steps:   0%|          | 46/1000000 [08:33<3081:24:09, 11.09s/it, loss=0.0169, lr=0.004, norm_target=13]Steps:   0%|          | 46/1000000 [08:44<3081:24:09, 11.09s/it, loss=0.096, lr=0.004, norm_target=13] Steps:   0%|          | 47/1000000 [08:44<3081:07:34, 11.09s/it, loss=0.096, lr=0.004, norm_target=13]Steps:   0%|          | 47/1000000 [08:55<3081:07:34, 11.09s/it, loss=0.135, lr=0.004, norm_target=13.4]Steps:   0%|          | 48/1000000 [08:55<3081:13:03, 11.09s/it, loss=0.135, lr=0.004, norm_target=13.4]Steps:   0%|          | 48/1000000 [09:06<3081:13:03, 11.09s/it, loss=0.00461, lr=0.004, norm_target=13.4]Steps:   0%|          | 49/1000000 [09:06<3080:56:56, 11.09s/it, loss=0.00461, lr=0.004, norm_target=13.4]Steps:   0%|          | 49/1000000 [09:17<3080:56:56, 11.09s/it, loss=0.00682, lr=0.004, norm_target=13.4]Steps:   0%|          | 50/1000000 [09:17<3103:23:41, 11.17s/it, loss=0.00682, lr=0.004, norm_target=13.4]Steps:   0%|          | 50/1000000 [09:29<3103:23:41, 11.17s/it, loss=0.0128, lr=0.004, norm_target=13.4] Steps:   0%|          | 51/1000000 [09:29<3096:02:09, 11.15s/it, loss=0.0128, lr=0.004, norm_target=13.4]Steps:   0%|          | 51/1000000 [09:40<3096:02:09, 11.15s/it, loss=0.221, lr=0.004, norm_target=13.7] Steps:   0%|          | 52/1000000 [09:40<3091:46:40, 11.13s/it, loss=0.221, lr=0.004, norm_target=13.7]Steps:   0%|          | 52/1000000 [09:51<3091:46:40, 11.13s/it, loss=0.055, lr=0.004, norm_target=13.7]Steps:   0%|          | 53/1000000 [09:51<3088:26:15, 11.12s/it, loss=0.055, lr=0.004, norm_target=13.7]Steps:   0%|          | 53/1000000 [10:02<3088:26:15, 11.12s/it, loss=0.0606, lr=0.004, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:02<3086:10:20, 11.11s/it, loss=0.0606, lr=0.004, norm_target=13.7]Steps:   0%|          | 54/1000000 [10:13<3086:10:20, 11.11s/it, loss=0.132, lr=0.004, norm_target=13.7] Steps:   0%|          | 55/1000000 [10:13<3084:14:57, 11.10s/it, loss=0.132, lr=0.004, norm_target=13.7]Steps:   0%|          | 55/1000000 [10:24<3084:14:57, 11.10s/it, loss=0.157, lr=0.004, norm_target=14.1]Steps:   0%|          | 56/1000000 [10:24<3083:37:15, 11.10s/it, loss=0.157, lr=0.004, norm_target=14.1]Steps:   0%|          | 56/1000000 [10:35<3083:37:15, 11.10s/it, loss=0.152, lr=0.004, norm_target=14.1]Steps:   0%|          | 57/1000000 [10:35<3082:17:08, 11.10s/it, loss=0.152, lr=0.004, norm_target=14.1]Steps:   0%|          | 57/1000000 [10:46<3082:17:08, 11.10s/it, loss=0.0937, lr=0.004, norm_target=14.1]Steps:   0%|          | 58/1000000 [10:46<3081:46:50, 11.10s/it, loss=0.0937, lr=0.004, norm_target=14.1]Steps:   0%|          | 58/1000000 [10:57<3081:46:50, 11.10s/it, loss=0.0447, lr=0.004, norm_target=14.1]Steps:   0%|          | 59/1000000 [10:57<3082:39:51, 11.10s/it, loss=0.0447, lr=0.004, norm_target=14.1]Steps:   0%|          | 59/1000000 [11:08<3082:39:51, 11.10s/it, loss=0.0552, lr=0.004, norm_target=14.4]Steps:   0%|          | 60/1000000 [11:08<3082:29:58, 11.10s/it, loss=0.0552, lr=0.004, norm_target=14.4]