INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.14 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations
WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:
    PyTorch 2.1.1+cu121 with CUDA 1201 (you have 2.1.1+cu118)
    Python  3.9.18 (you have 3.9.19)
  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)
  Memory-efficient attention, SwiGLU, sparse and more won't be available.
  Set XFORMERS_MORE_DETAILS=1 for more details
INFO:__main__:Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'clip_sample_range', 'prediction_type', 'variance_type', 'timestep_spacing', 'thresholding', 'dynamic_thresholding_ratio', 'sample_max_value'} was not found in config. Values will be initialized to default values.
{'scaling_factor'} was not found in config. Values will be initialized to default values.
{'cross_attention_norm', 'resnet_skip_time_act', 'addition_time_embed_dim', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'addition_embed_type', 'upcast_attention', 'conv_out_kernel', 'mid_block_only_cross_attention', 'only_cross_attention', 'time_cond_proj_dim', 'transformer_layers_per_block', 'num_attention_heads', 'class_embed_type', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'encoder_hid_dim', 'encoder_hid_dim_type', 'use_linear_projection', 'class_embeddings_concat', 'resnet_time_scale_shift', 'mid_block_type', 'dual_cross_attention', 'timestep_post_act', 'resnet_out_scale_factor', 'conv_in_kernel', 'time_embedding_dim', 'time_embedding_type'} was not found in config. Values will be initialized to default values.
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 10000000
INFO:__main__:  Num Epochs = 1
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:__main__:  Gradient Accumulation steps = 4
INFO:__main__:  Total optimization steps = 1000000
set seed 2940
saved_models/nj_models/single_capv7_prior_seed2940_rep2/dog6/ti_cnetv4_prior_mlm0001_dog6_mprob015_mbatch25_nj_nj/src/command.txt command_path
nj_train.py item
--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5 item
--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/dog6 item
--learnable_property=object item
--placeholder_token1=<dog6> item
--train_prior_concept1=dog item
--eval_prior_concept1=dog item
--resolution=512 item
--train_batch_size=1 item
--gradient_accumulation_steps=4 item
--learning_rate=5e-4 item
--lr_scheduler=constant item
--normalize_mask_embeds=0 item
--lr_warmup_steps=0 item
--output_dir=saved_models/nj_models/single_capv7_prior_seed2940_rep2/dog6 item
--seed=2940 item
--mask_tokens=[MASK] item
--lambda_mlm=0 item
--freeze_mask_embedding=1 item
--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt item
--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt item
--mask_prob=0.15 item
--mlm_target=masked item
--mlm_batch_size=25 item
--scale_lr item
--eval_prompt_type=living item
--train_prompt_type=pet item
--silent=0 item
--rev=0 item
--normalize_target1=0 item
--caption_root=../datasets_pkgs/captions/v7 item
--run_name=ti_cnetv4_prior_mlm0001_dog6_mprob015_mbatch25_nj_nj item
--include_prior_concept=1 item
32 norm_num_groups
320 block_out_channels[0]
32 norm_num_groups
None mask_token_ids
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
seeded
captions_pet_relations	29376
captions_pet_styles	378
captions_pet_backgrounds	552
captions_pet_human_interactions	3528
captions_pet_wearings	4560
Steps:   0%|          | 0/1000000 [00:00<?, ?it/s]True accepts_keep_fp32_wrapper
{'keep_fp32_wrapper': True} extra_args
INFO:__main__:STEP 0 Running validation... 
 Generating 7 images with prompt: ['a <dog6> dog in the jungle', 'a <dog6> dog with a city in the background', 'a <dog6> dog with a mountain in the background', 'a <dog6> dog on top of a purple rug in a forest', 'a <dog6> dog in a chef outfit', 'a <dog6> dog in a police outfit', 'a cube shaped <dog6> dog'].

  0%|          | 0/25 [00:00<?, ?it/s][A
  4%|â–         | 1/25 [00:00<00:10,  2.29it/s][A
  8%|â–Š         | 2/25 [00:00<00:09,  2.47it/s][A
 12%|â–ˆâ–        | 3/25 [00:01<00:08,  2.54it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:01<00:08,  2.54it/s][A
 20%|â–ˆâ–ˆ        | 5/25 [00:01<00:07,  2.51it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:02<00:08,  2.33it/s][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:02<00:08,  2.24it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:03<00:07,  2.34it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:03<00:06,  2.43it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:04<00:06,  2.49it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:04<00:05,  2.52it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:04<00:05,  2.47it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:05<00:05,  2.16it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:05<00:04,  2.21it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:06<00:04,  2.31it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:06<00:03,  2.38it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:07<00:03,  2.45it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:07<00:02,  2.48it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:07<00:02,  2.52it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:08<00:02,  2.37it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:08<00:01,  2.27it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:09<00:01,  2.19it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:09<00:00,  2.27it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:10<00:00,  2.34it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:10<00:00,  2.38it/s][A439510307 worker_seed
439510308 worker_seed
439510309 worker_seed
439510306 worker_seed
Traceback (most recent call last):
  File "/home/twkim/project/rich_context/padding/nj_train.py", line 984, in <module>
    main()
  File "/home/twkim/project/rich_context/padding/nj_train.py", line 896, in main
    images,validation_prompts = log_validation(
  File "/home/twkim/project/rich_context/padding/nj_train.py", line 154, in log_validation
    images = pipeline(validation_prompts, num_inference_steps=25, generator=generator,
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py", line 786, in __call__
    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/models/autoencoder_kl.py", line 264, in decode
    decoded = self._decode(z).sample
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/models/autoencoder_kl.py", line 251, in _decode
    dec = self.decoder(z)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/models/vae.py", line 270, in forward
    sample = up_block(sample, latent_embeds)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/models/unet_2d_blocks.py", line 2274, in forward
    hidden_states = resnet(hidden_states, temb=temb)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/twkim/project/rich_context/padding/./packages/diffusers/models/resnet.py", line 596, in forward
    hidden_states = self.norm1(hidden_states)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 279, in forward
    return F.group_norm(
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/torch/nn/functional.py", line 2558, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 896.00 MiB. GPU 0 has a total capacty of 23.69 GiB of which 782.75 MiB is free. Process 3362692 has 16.22 GiB memory in use. Including non-PyTorch memory, this process has 6.70 GiB memory in use. Of the allocated memory 5.66 GiB is allocated by PyTorch, and 291.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:11<00:00,  2.21it/s]
Steps:   0%|          | 0/1000000 [00:26<?, ?it/s]
Traceback (most recent call last):
  File "/home/twkim/anaconda3/envs/context/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1023, in launch_command
    simple_launcher(args)
  File "/home/twkim/anaconda3/envs/context/lib/python3.9/site-packages/accelerate/commands/launch.py", line 643, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/twkim/anaconda3/envs/context/bin/python', 'nj_train.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--train_data_dir1=/data/twkim/diffusion/personalization/collected/images/dog6', '--learnable_property=object', '--placeholder_token1=<dog6>', '--train_prior_concept1=dog', '--eval_prior_concept1=dog', '--resolution=512', '--train_batch_size=1', '--gradient_accumulation_steps=4', '--learning_rate=5e-4', '--lr_scheduler=constant', '--normalize_mask_embeds=0', '--lr_warmup_steps=0', '--output_dir=saved_models/nj_models/single_capv7_prior_seed2940_rep2/dog6', '--seed=2940', '--mask_tokens=[MASK]', '--lambda_mlm=0', '--freeze_mask_embedding=1', '--cls_net_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/cls_net_100000_ckpt.pt', '--mask_embed_path=saved_models/mlm_models/sd1_contextnetv4_nonpadding_1e4_unnorm_mprob015_batch150/checkpoints/checkpoint-100000/mask_embeds_100000_ckpt.pt', '--mask_prob=0.15', '--mlm_target=masked', '--mlm_batch_size=25', '--scale_lr', '--eval_prompt_type=living', '--train_prompt_type=pet', '--silent=0', '--rev=0', '--normalize_target1=0', '--caption_root=../datasets_pkgs/captions/v7', '--run_name=ti_cnetv4_prior_mlm0001_dog6_mprob015_mbatch25_nj_nj', '--include_prior_concept=1']' returned non-zero exit status 1.
